{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the CMDBsyncer","text":"<p>Rule based and modular system to syncronize hosts between Checkmk, Netbox, I-Doit and all others systems with interfaces and APIs. Main goal is the complete organization of the hosts based on CMDB systems and a full automation of Checkmk.</p> <p> </p>"},{"location":"#main-functions","title":"Main Functions","text":"<ul> <li>Web Interface with Login, 2FA and User management</li> <li>All configuration besides Installation in Web Interface</li> <li>Simple Plugin API to integrate own Data Sources</li> <li>Various Debug Options with the ./cmdbsyncer command</li> <li>Rules to control the Synchronization:<ul> <li>Based on Host Attributes</li> <li>Attribute Rewrites</li> <li>Filters fur Hosts and Attributes</li> </ul> </li> <li>Action Rules for Actions in Ansible, Checkmk, Netbox etc.</li> <li>Web Based management for Account Credentials.</li> <li>Encryption of Secrets</li> <li>Cron Management</li> <li>Monitoring Integration</li> <li>Jinja Support for Configuration and Rules</li> <li>RestAPI</li> <li>Ansible Support as Inventory Source</li> </ul>"},{"location":"#modules","title":"Modules","text":"<ul> <li> <p>Checkmk</p> <ul> <li>Mange full Host Lifecycle (creation, labels, folders, deletion, rules)</li> <li>Tested with more than 140,000 Hosts</li> <li>Sync and Update all possible Host Attributes/ Tags/ Labels</li> <li>Full Support of API Bulk Operations</li> <li>Full management of Checkmk Folders</li> <li>Folder Pool Feature to split big amounts of Hosts automatically between folders (and therefore sites).</li> <li>Creation of Host-, Contact- and Service Groups</li> <li>Create Host Tags and Host Tag Groups</li> <li>Create BI Aggregations</li> <li>Create all types of Setup Rule</li> <li>Integrated options to prevent to many Updates in Checkmk</li> <li>Full Multiprocessing support for Calculations</li> <li>Command to Active Configuration</li> <li>Command to Bake and Sign Agents</li> <li>Management of Checkmk (Fallback) users (Create/ Delete/ Reset Password/ Disable Login)</li> <li>Inventory for Host Attributes (need e.g. for Ansible, like on which site is server on)</li> <li>Inventory of Service Informations, Labels, Tags and HW/SW Inventory possible (can be used e.g. for I-Doit Sync)</li> <li>Create DCD Rules</li> <li>Create and Manage Password Store (Encryption) entries</li> <li>Automatic Detection of the Checkmk Version to use the correct API Payloads</li> </ul> </li> <li> <p>Ansible</p> <ul> <li>Rule Based Inventory Source</li> <li>All Functions for Checkmk Agent Management (Installation, TLS Registration, Bakery Registration)<ul> <li>Linux and Windows</li> </ul> </li> <li>All functions for Checkmk(OMD) Site Management (Update Sites, Create Sites etc.)<ul> <li>Automatic Download of Checkmk Versions if wanted.</li> </ul> </li> </ul> </li> <li> <p>Netbox</p> <ul> <li>Rulebased Export and Import Devices and VMs to/from Netbox</li> <li>Automatic creation of Categories if wanted.</li> <li>Export of Sites</li> <li>Export Interfaces</li> <li>Export IPAM</li> <li>Export Contacts</li> <li>And more</li> </ul> </li> <li> <p>PRTG</p> <ul> <li>Import Objects from PRTG to sync them to Checkmk</li> </ul> </li> <li> <p>I-DOIT</p> <ul> <li>Rulebased Export and Import Devices to/from I-Doit</li> <li>Template Based</li> </ul> </li> <li> <p>BMC Remedy</p> <ul> <li>Limited import from BMC Remedy</li> </ul> </li> <li> <p>Cisco DNA</p> <ul> <li>Import devices and their Interface Information</li> </ul> </li> <li> <p>CSV</p> <ul> <li>Manage Hosts based on CSV File (Import Source)</li> <li>Add Addional Informationen from CSV Files to your Hosts (eg. Overwrite IP Addresses)</li> </ul> </li> <li> <p>LDAP</p> <ul> <li>Import Objects from LDAP Directories</li> </ul> </li> <li> <p>RestAPI</p> <ul> <li>Import of Custom Rest APIs</li> </ul> </li> <li> <p>JSON</p> <ul> <li>Import of Json File Structures</li> </ul> </li> <li> <p>Jira CMDB on Prem and Cloud:</p> <ul> <li>Import Objects</li> </ul> </li> <li> <p>JDisc</p> <ul> <li>Import Objects</li> </ul> </li> <li> <p>Vmware</p> <ul> <li>Import Attributes</li> <li>Export Attributes to Vmware VMs</li> </ul> </li> <li> <p>MySQL</p> <ul> <li>Import and Inventorize Mysql Database Tables</li> </ul> </li> <li> <p>Mssql/ FreeDTS/ ODBC</p> <ul> <li>Import and Inventorize all kinds of ODBC based Database Connections</li> </ul> </li> </ul>"},{"location":"advanced/jinja_functions/","title":"Custom Jinja Functions the Syncer offers","text":""},{"location":"advanced/jinja_functions/#merge_list_of_dicts","title":"merge_list_of_dicts()","text":"<p>If you have, for example in your Attributes, a List of Dictionaries like this: </p> <pre><code>location = [{\"site\":\"\"},{\"section\":\"\"},{\"level\":\"\"},{\"room\":\"\"},{\"description\":\"\"},{\"note\":\"\"}]\n</code></pre> <p>Then you can use this Jinja Syntax to pick given values in the rewrite</p> <pre><code>{{ merge_list_of_dicts(location)['room'] }}\n</code></pre>"},{"location":"advanced/jinja_functions/#get_list","title":"get_list()","text":"<p>This helper converts a Attribute List of given List into a Python list, which is used in some of the Syncers functions. See Hostags for example.</p>"},{"location":"advanced/jinja_functions/#cmk_cleanup_tag_id","title":"cmk_cleanup_tag_id()","text":"<p>Cleans a String so that it can serve as Checkmk Hosttag ID. Invalid Chars are replaced by underscore.</p>"},{"location":"advanced/jinja_functions/#get_ip4_network","title":"get_ip4_network()","text":"<p>Access to a python Function from the module ipaddress. If you call it, <code>ipaddress.ip_interface()</code> is called.</p> <p>Test</p>"},{"location":"advanced/own_plugins/","title":"Plugins","text":"<p>If you want to build a plugin to fetch any kind of data into the CMK Syncer, you learn here how to do that.</p> <p>I recommend using the file plugins/example_source.py as base. Inside this file are comments who describe the functions needed to perform the import. Most Logic will be the part to query the data. The Cmdbsyner part is elementary. The full documentation of API Functions can be found here</p>"},{"location":"advanced/own_plugins/#steps-for-a-simple-plugin","title":"Steps for a simple Plugin","text":"<p>(Refer to the example_source.py to follow that list) </p> <ol> <li>Register a Command Argument, needed to call the Plugin</li> <li>Register needed Parameters, normally just the Account name so that you can fetch e.g. the Credentials from the config.</li> <li>Then actually Fetch the Account config</li> <li>Build the Fetch Logic for your API, so that you have a List of Hosts and their Labels as Dictionary</li> <li>Iterate your Hosts and get the reference based on the hostname</li> <li>Set account to it to prevent overwrite from different source</li> <li>Overwrite the Labels</li> <li>Save the object</li> <li>Add some Print Output if needed</li> <li>Done :) </li> </ol> <p>Notes: - Only Import syncer functions from syncerapi.v1, otherwise Updates can break your plugins</p>"},{"location":"advanced/plugin_api/","title":"Syncer API","text":"<p>For your Plugins, please only import from syncerapi.v1 Otherwise, we can't guarantee that updates won't break something in your scripts.</p>"},{"location":"advanced/plugin_api/#functions","title":"Functions","text":""},{"location":"advanced/plugin_api/#base","title":"Base:","text":"<pre><code>from syncerapi.v1 import XXX\n</code></pre> Function Description Host The Central Host Object get_account Get the Account Config by Name (Automated with Plugin Base Class) register_cronjob Register a Function to Appear as Cronjob cc (Color Codes) Use to Print  with nice Colors render_jinja Render given String with Jinja"},{"location":"advanced/plugin_api/#core","title":"Core","text":"<pre><code>from syncerapi.v1.core import XXX\n</code></pre> Function Description logger Add Custom Log Events app Flask App Object app_config Access to the Global Config cli Register CLI Params Plugin Base Class for your Plugins (see below)"},{"location":"advanced/plugin_api/#inventory","title":"Inventory","text":"<p><pre><code>from syncerapi.v1.inventory import XXX\n</code></pre> - run_invenentory</p>"},{"location":"advanced/plugin_api/#host-object-api","title":"Host Object API","text":"<p>The Host Object, you can use inside your Import and Export Plugins.  It's the reference to the the list of your Hosts, or to update a Single one (Host.get_host(name)) It supports the following Methods:</p> Method Description get_host(hostname) Get the Host Object to add Attributes get_export_hosts() Return only Hosts, no Objects for e.g. Loop rewrite_hostname(old_name, template, attribute) Shortcut to render_jinja replace_label(key, value) Replace given Label with new Value update_host(labels) Replace all Labels of host. update_inventory(key, inventory) Update hosts inventory get_inventory() Get hosts Inventory add_log(entry) Add Log Entry to Host set_account(config) Set import Account, alsways use to checkif allowed to save save() Save Changes you made on the object"},{"location":"advanced/plugin_api/#plugin-base-class","title":"Plugin Base Class","text":"<p>The Plugin() is the Base class for your Plugin. If you're using it, you can use some automatic benefits like logging and a central Request Class which can be debugged with the normal Syncer Switches.</p> <p><pre><code>class YourPlugin(Plugin):\n    name = \"Your Plugins Name (for log)\"\n    source = \"Key used in log\"\n\n    def __init__(self, account):\n        super().__init__(account)\n        # Your Stuff\n</code></pre> If you have your own _init_() just make sure to call super() in order that the e.g. the config is processed. </p>"},{"location":"advanced/plugin_api/#default-methods-and-variables","title":"Default Methods and Variables:","text":"Function/ Method Description name (string) The Name of the Plugin Actions (for log) source (string) Type of Action, usefull to filter log config (dict) The Accounts configuration log_details (list(tuple)) Append Tuples (name, details) which will laterappear in the log view which you have in the GUI inner_request(method, url, data, headers) Use for all HTTP Requests.Has logging, makes your Plugin support save_requests anddry_run"},{"location":"advanced/plugin_api/#log-details","title":"Log Details","text":"<p>When calling self.log_details.append((\"Count\", 12 )) you can add a metric named Count with the Value 12 to the Log entry which is generated when you run your plugin. You can use any Name you want, you can also log every type of Object which can casted to string. But If one of your Names contains \"error\", the whole Log Entry is marked as error entry. This can then show UP in your Monitoring.</p>"},{"location":"ansible/","title":"Ansible Integration","text":"<p>The CMDB Syncer contains Ansible Endpoints and a set of Ansible Playbooks. As of now, you can basically controll all of your own playbooks with rule based variables from the syncer, or use the providedd ones for Update and Register of Checkmk Agents (Linux/ Windows) or the Managementt and Installation of Checkmk Sites on your Servers.</p>"},{"location":"ansible/#config-tricks","title":"Config Tricks","text":"<p>If you want to refer to Passwords in your Syncer Configuration, you can use an Integrated Marco called ACCOUNT who connects you to every Field which you can set in the Account config.  The Syntax is MACRONAME:ACCOUNTNAME:FIELDNAME.</p> <p>Therefore , to get the Password of account cmk, it would look like: <pre><code>{{ACCOUNT:cmk:password}}\n</code></pre></p>"},{"location":"ansible/#general","title":"General","text":"<p>Inside the Ansible subfolder, you will find a set of inventory plugins for Ansible. These are for use with the ansible-playbook command, behind the -i parameter.</p> <p>As of now, these are:</p> File Description inventory General Inventory source for local installation docker_inventory Inventory source when running in docker rest_inventory Example for Inventory Source using the Rest API of Syncer cmk_server_inventory Special source for use with the cmk_server_mngm.yml playbook cmk_server_docker_inventory Like above <p>Also you find two playbooks and two roles:</p> File Description cmk_agent_mngmt.yml The complete Managment of the Agent Installations of Checkmk cmk_server_mngmnt.yml The Update and Installation of Checkmk Sites and Versions. <p>From here you can copy and adapt these scripts to your need (when so, prefix with local_) or just use the provided ones.</p>"},{"location":"ansible/#use-the-ansible-playbooks-directly-inside-syncer","title":"Use the Ansible Playbooks directly inside Syncer","text":"<p>If you not have an Ansible installation or the Ansible Knowledge, you can just run the included stuff from inside the Syncers Folder. Just make sure to install the additional requirements at the first time: pip install -r ./ansible/requirements.txt</p> <p>After that, the Workfloww is: </p> <ul> <li>Change into the CMDB Syncer Directory</li> <li>Load his environment (source ENV/bin/activate)</li> <li>Change to the ansible subdir: cd ./ansible</li> <li>You are Ready</li> </ul>"},{"location":"ansible/#remote-installation","title":"Remote Installation","text":"<p>If you want to use the Syncers script, but from adifferentt server and to connectt via Rest API, these are the Steps:</p> <ul> <li>Checkout the Repo</li> <li>Copy the Inventory File: cp rest_inventory local_rest_inventory</li> <li>Edit the File and set the URL (beware of Proxy) to the Syncer Installation, and set a Secret:</li> <li> <p></p> </li> <li> <p>The Secret is set up in the Account:</p> </li> <li></li> <li>You are Ready</li> </ul>"},{"location":"ansible/#run-ansible","title":"Run Ansible","text":"<p>You can run Ansible now with the wanted Play books. I would recommend to always check with the debug_host feature of the Ansible Module, which Variables are set. From here one, it's normal ansible:</p> <p><code>ansible-playbook -i INVENTORY_SOURCE --limit somehost cmk_agent_mngmt.yml</code></p>"},{"location":"ansible/cmk_agents/","title":"General","text":"<p>The cmk_agent_mngmt.yml Playbook contains everything to manage the Installation and the Bakery and TLS Registrations of your Checkmk Agents. This works for Linux and Windows.</p> <p>The job of the Syncer is, to dynamical provide variables to the Ansible Playbook, that Ansible always know what to do with each Host.</p> <p>Information are inventorized for example from Checkmk self, like on which site the host is, or if the Checkmk Agent reports for example TLS errors. Also, all kind of known attributes can be used. And the Syncer Rules then created dynamic all Variables for Ansible.</p>"},{"location":"ansible/cmk_agents/#functions","title":"Functions","text":"<ul> <li>Support for Linux and Windows</li> <li>Install Checkmk Agents</li> <li>Register Checkmk Bakery</li> <li>Register TLS for Checkmk</li> <li>Discover Host in Checkmk</li> <li>Bake and Sign Agents (See Checkmk part)</li> <li>Restart Checkmk (See Checkmk part)</li> </ul>"},{"location":"ansible/cmk_agents/#inventorize-checkmk","title":"Inventorize Checkmk","text":"<p>To get the current Status Information about the Host, like is the Agent on Error, is the Bakery registered the inventory function of the Syncer is used. All Information found will be added to the Syncers Database. </p> <p>The Command is: <code>./cmdbsyncer checkmk inventorize_hosts account</code>. </p> <p>After the run, you can verify what the Inventory found, when you check a Host in the Frontend and Scroll to inventory:</p> <p></p>"},{"location":"ansible/cmk_agents/#ansible-variables","title":"Ansible Variables","text":"<p>Next, you need to seed Variables and Conditions. This is necessary for Ansible to know if an Action is due, or which Credentials are used.</p> <p>The following Variables existing in the Ansible Role. You learn later how to set them:</p> Variable Description cmk_user User for Auth in Checkmk and API Operations cmk_secret The Automation Secret for the User cmk_server The Site specifc Server for Registrations (Distributed Monitoring) cmk_main_site Master Site cmk_main_server Master Sites Address (without https:// or other paths) cmk_server Local Site specifc Address (without https:// or other paths) cmk_site Use best from cmk inventory (Rewrite: cmk__label_site to cmk_site) cmk_install_agent True if Agent has to be installed cmk_register_tls True if TLS Registration has to be done cmk_register_bakery True if Bakery Registration as to be done cmk_register_central_bakery True if Bakery Registration for no Distributed Bakery Setup cmk_delete_manual_files Set True if you delte the Checkmk Files on the Server cmk_linux_tmp Temp dir which is used on Linux cmk_agent_receiver_port Port for Agent TLS Registration cmk_discovery Trigger Checkmk Discovery on Host cmk_windows_tmp Temo dir on Windows Server cmk_server_port Overwrite the default 443 port of Checkmk cmk_agent_port For Firewall: Changed Agent port from 6556 to custom cmk_server_ip Use a IP instead of a Hostname when DNS is not available. Also need for Firewall config configure_firewall Enable Firewall Configuration for RedHat <p>Some of them are already part of the Inventory after you invenorized Checkmk others a Hardcoded like Credentials. And finally, there are the condition based, like cmk_register_bakery which only should be true, if the registration is missing. </p> <p>To start easier, you can create a Set of Default rules with this command: </p> <p>`./cmdbsyncer rules import_rules ./example_rules/ansibe_cmk_rules.py</p>"},{"location":"ansible/cmk_agents/#syncer-configuration","title":"Syncer Configuration","text":""},{"location":"ansible/cmk_agents/#settings","title":"Settings","text":"<p>You can set which Hosts you want to manage via Ansible, or deploy custom Variables to some Hosts with the Ansible Rules. The normal Filter and Rewrite Function also apply here. </p> <p>The Conditions are configured in: Rules \u2192Ansible \u2192Custom Variables </p> <p>To set the Credentials, Ansible should use contact Checkmk, see here: </p> <p>Example how to Install the Agent when a given Service Output was found: </p> <p>Likewise, you can configure if to register to bakery or the TLS. Filter for example for the TLS Error message in the Service Output. Best is to seed defaults as descripted above, to have more examples which just need to be adapted a bit.</p>"},{"location":"ansible/cmk_agents/#passwords-and-account-data-as-variables","title":"Passwords and Account Data as Variables","text":"<p>You don't need to set the Password value directly in the settings, you can also read it from your Accounts. For that, instead of the Password, just Enter the Macro: {{ACCOUNT:NAME:password}}. Account needs to be uppercase, Name is the Account Name, password can also be every other field or custom field in your account Settings.</p> <p></p>"},{"location":"ansible/cmk_agents/#redhat-firewalls","title":"RedHat Firewalls","text":"<p>You can configure the Firewall Zones and the Checkmk Server IPs to let the Syncer configure the Firewall for you.</p> <p>You just need to set <code>configure_firewall</code> and also the <code>cmk_server_ip</code></p>"},{"location":"ansible/cmk_agents/#run-the-job","title":"Run the job","text":""},{"location":"ansible/cmk_agents/#debugging","title":"Debugging","text":"<p>Before you run anything in Ansible, use the debug_host feature to check if the Outcome is what you want: <code>./cmdbsyncer ansible debug_host HOSTNAME</code> The command will tell you all variable outcomes you will have in Ansible.</p>"},{"location":"ansible/cmk_agents/#ansible-command","title":"Ansible Command","text":"<p><code>ansible-playbook -i inventory cmk_agent_mngmt.yml</code></p> <p>Please just replace the inventory source if needed.</p>"},{"location":"ansible/cmk_agents/#windows-clients-and-kerberos","title":"Windows Clients and Kerberos","text":"<p>If you have your Linux Server prepared for Kerberos, you can use it with the Syncer to Update/ Install/ Register Windows Agents. This is the Settings you will need for that:</p> <p></p>"},{"location":"ansible/cmk_agents/#known-problems","title":"Known Problems","text":""},{"location":"ansible/cmk_agents/#distributed-bakery-not-supported-yet-in-api","title":"Distributed Bakery not supported yet in API","text":"<p>The Checkmk API currently can't reflect a Distributed Setup. Therefore Ansible fails to Download Agents from a remote site.  As Workarround you can set an Apache Reverseproxy Rule, to Forward only the Bakery API Requests to the Main Site.</p> <pre><code>SSLProxyEngine On\n\nSSLProxyCheckPeerCN off\n\nRewriteEngine On\n\nRewriteRule /sitename/check_mk/api/1.0/domain-types/agent/(.*)$ https://mastersite/sitename/check_mk/api/1.0/domain-types/agent/$1 [P]\n</code></pre> <p>This config must be put into the VirtualHost config for Port 443 on your remote Site.</p>"},{"location":"ansible/cmk_sites/","title":"Checkmk Site Management","text":"<p>The Included Playbook cmk_server_mngmnt.yml makes use of the following functions:</p> <ul> <li>Installation of Checkmk Versions</li> <li>Creation of Checkmk Sites</li> <li>Updates of Checkmk Sites</li> </ul>"},{"location":"ansible/cmk_sites/#how-it-works","title":"How It works","text":"<p>Configure your Checkmk Target Version, and your Checkmk Sites inside the Syncer.  Then run the Playbook.  The Configuration can be Found in Rules\u2192 Checkmk</p> <p>Now the Details:</p>"},{"location":"ansible/cmk_sites/#cmk-server-settings","title":"CMK Server Settings","text":"<p>Rules \u2192Checkmk \u2192CMK Server Settings  Here you set the Target Version you want to use. The needed information can be found on the Checkmk Download Page:</p> <p></p> <p>If you place the Checkmk Installation Package under /tmp it will be used. If not, the System will try to download it, using the supplied credentials. Then it's transferred to your remote server. That means these servers do not need an internet connection.</p> <p>When you create a rule, you find the following options:</p> Option Description Name Name of config set Server User User for Ansible to connect to the Server. Sudo needs to be possibe CMK Version Version's String like 2.1.0p19 CMK Edition Enterprise or RAW CMK Version Filename Filename like found on the cmk download server, example: check-mk-enterprise-{{CMK_VERSION}}_0.bullseye_amd64.deb Inital Password This password will be set for new sites Subscription Username/ Password Your Checkmk Subscription Account <p>Note: For the CMK Version Filename, you can use the Placeholders {{CMK_VERSION}} and {{CMK_EDITION}}</p>"},{"location":"ansible/cmk_sites/#cmk-sever-sites","title":"CMK Sever Sites","text":"<p>Rules \u2192Checkmk \u2192CMK Server Sites  As Second you add all your Sites here. Every Entry references to a Server Setting entry. Make sure that the operating system will match to the Server Settings.</p> Option Description name Site Name Server Address Address of Server for SSH (without protocoll) Settings Master Select the CMK Server Settings Entry <p>As a current limit, the System can only manage one Checkmk Site per Server. </p>"},{"location":"ansible/cmk_sites/#custom-ansible-variables","title":"Custom Ansible Variables","text":"<p>For each Site, you can set Ansible Custom Variables if you need special Settings to reach the site. That could be every Variable, supported by Ansible</p> <p></p>"},{"location":"ansible/cmk_sites/#run-the-automation","title":"Run the automation","text":"<p>With the settings done, you can run Ansible now.</p> <p><code>ansible-playbook -i cmk_server_inventory cmk_server_mngmt.yml</code></p>"},{"location":"basics/accounts/","title":"Accounts","text":"<p>The Syncer uses accounts, which enables you to pass all kinds of information to your plugins. Here you will find how they work. Refer to the Module Account Sections to find about all the needed options.</p> <p>You will find the settings in Accounts</p>"},{"location":"basics/accounts/#basic-fields","title":"Basic Fields","text":"Field Description Name Reference Name for the Account, used also in CI Type Type of Account, only checks validation Is Master This Account can overwrite other accounts when import data Is Object Will not be exported as host, but attributes can be used in the rules Object Type For future function to help filter objects in a better way Address URL or Hostname to the System, depending on the Module Username Username for the Account Password Password or Secret for the Account Custom Fields Extra Fields used by plugins <p>Hint: Maybe you don't need all the Fields. So, an API for example, could only need a Secret, so you would only need Name, Address and Password.</p>"},{"location":"basics/accounts/#about-objects-and-object-types","title":"About Objects and Object Types","text":"<p>The flag <code>is Object</code>, basically does not add the imported Object into the Hosts view, but the Object view. But all Attributes of the Objects can still be accessed in Rule.  Currently also a object is not exported as Host to other Systems, but with the in 3.8 introduced \"Objects Filter\" (see below) you can filter that more flexible.</p>"},{"location":"basics/accounts/#the-object-types","title":"The Object Types","text":"<p>Object Types are assigned also on import. They help you later to better filter objects on exports, but some have even more functions.</p> <p>If the Object Type is set to Host, then the import will not save objects, which would have an invalid Hostname but log an error instead. </p>"},{"location":"basics/accounts/#additional-configurations","title":"Additional Configurations","text":"<p> In some cases, like when you create an Account for CSV Files or JSON Files, you need some special Model-Specific fields for the Parameters. In this case, just save the account once, and the Fields will appear automatically.</p>"},{"location":"basics/accounts/#documentations-by-account-type","title":"Documentations by Account Type","text":"<ul> <li>Checkmk</li> <li>Netbox</li> <li>Jira</li> <li>Inventorize Options</li> </ul>"},{"location":"basics/accounts/#almost-global-available-options","title":"(Almost) Global Available Options","text":"Field Description delete_host_if_not_found_on_import Enter a  Mongoengine Filter for a Field in Format fieldname:value to instantly delete hosts on import operations from the syncer, if the matching host is no longer part of this import. A Docu for Filters click here. You can add multiple Filters by separating them with two pipes (||). They are connected by AND then."},{"location":"basics/accounts/#extra-plugin-options","title":"Extra Plugin Options","text":"<p>In this section you can set plugin-based account options. That means even when you use the same account for different actions, you can still used action specific parts which you can configure here.</p>"},{"location":"basics/accounts/#object-filter","title":"Object Filter","text":"<p>When set, the Plugin only uses objects with the given types for the operation.</p> <p></p>"},{"location":"basics/accounts/#reference-fields","title":"Reference Fields","text":"<p>In your configuration, you can reference to Fields you set here. So, you can hide Passwords, for example. You just have to use the {{ACCOUNT:...}} Macro. Syntax is: <pre><code>{{ACCOUNT:&lt;ACCOUN_TNAME&gt;:&lt;ACCOUNT_FIELD_NAME&gt;}}\n</code></pre></p>"},{"location":"basics/accounts/#config-childs","title":"Config Child's","text":"<p>A config Child is just the Child of a Normal Account. It inherits every setting from there, but overwrites the Custom Fields and the Plugin Config (if set)</p> <p>In this way, you don't need to create multiple Accounts in the case you need e.g. multiple Filters or Plugin Settings for different Situations.</p>"},{"location":"basics/caching/","title":"Caching","text":"<p>Specially if you have servals thousands of hosts, it makes a difference if a process per host takes 1 Second or just a few Milli Seconds. So to speed Syncer processes up, a Cache is used. The Cache will automatically delete for a Host if the Import updates his Labels.  If you, of course, Change Rules, you need to delete this cache.  For that, you will find a \"Commit Changes\" link in the Navigation top right. </p> <p>From the Command line, you can call ./cmdbsyncer sys delete_cache</p> <p>For Normal operations now, everything will be fine. They process like Export just gone Take a bit longer at the first time, where the Cache is built with the operation.  But in some cases, that is not enough. As an Example, if the API Endpoints for Ansible take too long, they will run in a Timeout.  In these cases, you find an option to manually build this cache on the Command line Example for Ansible: ./cmdbsyncer ansible update_cache In my example for what I build this Feature, the Time went down from 171 Seconds to just 2 Seconds for the hole Process </p>"},{"location":"basics/change_colors/","title":"Changing the Colors of the Interface","text":"<p>In bigger environments with tests instances, it's helpful to change the colors of the Syncer GUI to tell the environemnts apart.</p> <p>That's possible in the local_config.py. You can use the Variable <code>STYLE_NAV_BACKGROUND_COLOR</code> to set an HTML Color for the Background, <code>SYLE_NAV_LINK_COLOR</code> to change the Color of the Navigation Links and finally <code>HEADER_HINT</code> to add also a free Text to the Header. That could be the environment Name.</p>"},{"location":"basics/conditions/","title":"Rule Conditions","text":"<p>Every Rule has a Condition. And you have the power to match everything. Hosts or attributes with different options. Make sure to set for the Condition, if an Attribute or a Host match is required. Sadly, the Frontend always shows all input fields due to current limitations. Also, it's required to set how the conditions should be applied.</p> <p></p> <p>They can match \"ANY\", what means one matching condition will be enough for the rule to match. If set to \"ALL\", all conditions need to match. Put \"Anyway\" and the Rule will match without condition.</p> <p></p>"},{"location":"basics/conditions/#match-faq","title":"Match FAQ","text":""},{"location":"basics/conditions/#match-if-a-attribute-does-not-exist-on-an-object","title":"Match if a Attribute does NOT exist on an object","text":"<ul> <li>Set <code>Tag Match</code> to <code>Match All (*)</code>, </li> <li>Set <code>Tag</code> to the Tag you don't want to exist, </li> <li>Set Checkbox <code>Tag Match Negate</code></li> <li>Value Match does not matter</li> </ul>"},{"location":"basics/conditions/#match-if-an-attribute-is-an-empty-string","title":"Match if an Attribute is an empty string","text":"<p>Hint 1: If you don't want to import an Empty Attribute, you can set this with <code>LABELS_IMPORT_EMPTY=False</code>, in your local_config.py Hint 2: This works like that since the current 3.8 Version</p> <ul> <li>Set <code>Tag Match</code> to the desired Attribute Name</li> <li>Set <code>Value Match</code> to <code>String Equal</code></li> <li>Let <code>Value Match</code> empty, since that is a empty String</li> </ul>"},{"location":"basics/cron/","title":"Cronjobs","text":"<p>The Syncer can handle the needed Cronjobs for your Automation. You can choose all the Modules the Syncer Offers, and pass an Account which contains the config. Config would for example be a path of an CSV File.</p> <p>To use the Feature, create a Cronjob Group:</p>"},{"location":"basics/cron/#cronjob-group","title":"Cronjob Group","text":"<p>Cronjobs \u2192 Cronjob Group</p> <p>Each Group as an Interval and a Time range in which it should run.  With the Group, you set then the Jobs you want to run, and they will run in that order. If a Job Crashes, the hole Group will stop.  That is to, for example, not to delete hosts if the import failed.</p>"},{"location":"basics/cron/#state-table","title":"State Table","text":"<p>Cronjobs \u2192 State Table</p> <p>The State table keeps one Entry for all of your Groups. There you see the Time when the job runs next, or the last message and if there are errors.</p> <p>If you want to reset jobs, just delete or edit these Entries.</p>"},{"location":"basics/cron/#run-the-jobs","title":"Run the Jobs","text":"<p>The Syncer does not have an integrated cron, so you need to call an Endpoint to enable everything. That can be done every 5 or 10 minutes.  The Command you need to start is:</p> <pre><code>./cmdbsyncer cron run_jobs\n</code></pre> <p>And here is the Example including loading the local environment:</p> <pre><code>*/5 * * * * cd /var/www/cmdbsyncer &amp;&amp; source ./ENV/bin/activate &amp;&amp; ./cmdbsyncer cron run_jobs\n</code></pre> <p>Or all in Docker:</p> <pre><code>*/5 * * * * docker exec CONTAINER_ID /srv/cmdbsyncer cron run_jobs\n</code></pre>"},{"location":"basics/custom_attributes/","title":"No Data source is perfect","text":"<p>But there is a solution: CMDB Syncer Supports the Rule-based assignment of new Attributes.</p> <p>It's the first possible Rule and works for all other Modules:</p> <p></p> <p>It defines a condition and an outcome:</p> <p></p> <p>The Design of the Rule is like in every other rule, you define a Condition.</p> <p></p> <p>Just the Outcome is special for every rule:</p> <p></p>"},{"location":"basics/custom_attributes/#create-real-custom-attributes-with-rewrites","title":"Create real Custom Attributes with Rewrites","text":"<p>In the Module-Specific Rewrite Section, it is since Version 3.3 possible to create New labels using Templates. Please refer to the Rewrite Attributes This is more powerful as this global option.</p>"},{"location":"basics/debug/","title":"Debug Requests","text":""},{"location":"basics/debug/#how-to-see-debug-responses","title":"How to see debug Responses","text":"<p>To see requests and response for API Calls, e.g. to debug the Checkmk Export,  you can enable the debug mode. </p> <p>Just see the example give here</p> <p>Beginning with 3.8, many commands simply support <code>--debug</code> which dynamical activates the Debug mode.</p>"},{"location":"basics/debug_rules/","title":"Debug Rules","text":"<p>The options you have can lead to a complex outcome. So, best is, to check this outcome on a set of hosts.</p>"},{"location":"basics/debug_rules/#from-version-38","title":"From Version 3.8","text":"<p>Since Syncer 3.8, debug_host is deprecated. This is of all the new Export types which would lead to too many commands.</p> <p>You now can simply add <code>--debug</code> and all Exceptions will Raise, and if you want to debug the outcome of the rules for a singe object, use the export command and add <code>--debug-rules=objectname</code>. You can combine that with <code>--debug</code> to let exceptions raise, but it's not required. ```</p>"},{"location":"basics/debug_rules/#legacy-before-38-deprecated","title":"Legacy before 3.8, deprecated","text":"<p>For that, every export module contains a debug_host option. It's called in the CLI, by the Module as identifier.</p> <p>See here the examples for Checkmk and Ansible:</p> <p></p> <p>If you then query a host, you see the tables with information about which Rules are applied and which attributes used;</p> <p></p>"},{"location":"basics/export/","title":"Export","text":"<p>Export is the Sync of CMDB Syncer Data to a target. Most likely is the Support for this target already included in the Syncer. Most users use Checkmk or Net box as target. But of course, it's possible to build export plugins in the same way as you build import Plugins. Also, Of course, they are more complicated, since they need more support for rules and want to have a Frontend integration.  </p>"},{"location":"basics/fileadmin/","title":"Fileadmin","text":"<p>If you work, for example, with a lot of CSV Files in your Setup, but you don't want to access the Shell all the time, you can enable a simple Fileadmin Panel. This will appear as: Filemanager  in the Panel</p> <p>To enable it, just create a folder /srv/cmdbsyncer-files and make sure the Syncer can write in it. This will Enable the Fileadmin. You can, of course, overwrite this Path by setting \"FILEADMIN_PATH\" in your local config. This could be a good Idea if you're using Docker and you want to mount a Volume into the Container.</p>"},{"location":"basics/filter/","title":"Filter Hosts and Whitelist","text":"<p>Every Module has a Filter Section. Here you can Blacklist/ Whitelist the Hosts you want to export, and do the same for Labels/ Attributes which you wan't to export along them.</p> <p>The Syncer will may have hundreds of Attributes for a host. Normally, you don't want to have them all, for example as Label in Checkmk. Therefore, you have to whitelist them here. </p>"},{"location":"basics/first_steps/","title":"First Steps","text":"<p>Depending on, if you are on docker or local, you need to change into the docker container or enable the Virtual Environment for the following functions</p>"},{"location":"basics/first_steps/#settings","title":"Settings","text":"<p>The Config contains to important Values you should overwrite in a local_config.py file. First is \"SECRET_KEY\". This one is used to secure the login cookie. You can change it anytime, but all users will be logged out by that. More important: \"CRYPTOGRAPHY_KEY\". This one is used to decode Passwords stored in the Database. If changed, you need to reset all Passwords. How to set the config see  here</p>"},{"location":"basics/first_steps/#create-first-user","title":"Create first User","text":"<p>When you have the Setup Done, you have to create a user to login into the Web interface.</p> <p><code>./cmdbsyncer sys create_user mail@address.org</code></p> <p>The command shows you a password. In case you have forgotten the password, our locked yourself out with the 2FA Function, this command will reset everything.</p>"},{"location":"basics/first_steps/#explore-the-command-line-options","title":"Explore the Command line Options","text":"<p>The Command Line offers you access to almost every function.  It's separated in different areas. So, you can go deeper and deeper into the options.</p> <p>Example:</p> <p></p>"},{"location":"basics/host_labels_inventory/","title":"Hosts, Labels and Inventory","text":"<p>CMDB Syncer works with Hosts, Labels and Inventory. So far so simple, but what is what?</p>"},{"location":"basics/host_labels_inventory/#hosts","title":"Hosts","text":"<p>A Host is any kind of Device. It's identified by his hostname, bound to a source and contains Labels and Inventory</p>"},{"location":"basics/host_labels_inventory/#labels-and-inventory","title":"Labels and Inventory","text":"<p>Labels and Inventory are mostly the same, but have an important difference. They both are Key:Value pairs, can be used in all Rules, Rewritten and Filtered.</p> <p>The difference is only how they are dealt with their creation. While the Labels are imported and fully under control of the Import Plugin, can inventory data come from multiple sources. Inventory Keys share their sources identify, as a prefix on their name.</p> <p>Example:</p> <ul> <li>csv__ipaddress:127.0.0.1</li> <li>csv__alias:Test Server</li> <li>srctest__service_name: Test Service</li> </ul> <p>In this example, you see Inventory Data of two sources, one is csv, the other is srctest. So, the plugin using the key csv, will control all keys with csv/ and the plugin with srctest as key, the others.</p>"},{"location":"basics/host_labels_inventory/#account-options-for-inventorize-scripts","title":"Account Options for Inventorize Scripts","text":"<p>To get the Inventory, every Module has an Inventorize Endpoint. This Endpoint is configured using the Account. For Example you can use the same Checkmk Account to Export and to Inventorize, but it needs some more Options then.</p> Option Description inventorize_key Which prefix should be used for the attributes names inventorize_match_by_domain (not everywhere available yet) if true, the Inventory Data will match by domain Name inventorize_match_attribute Set an attribute name, then the wanted value. e.g. application=dns. The Data is then only added to this hosts inventory, if the hosts has an application attribute containing dns. inventorize_collect_by_key Enter an Attribute name. If this Attribute Name is found on the Host, and Contains the Name of another Host, this other Host gets the Attribute added (numerated) containing his hostname inventorize_rewrite_collect_by_key Rewrite the the collect_by_key value with Jinja"},{"location":"basics/how_it_works/","title":"How it all works","text":"<pre><code>graph LR\nSD[Source Database]\nSC[Source CSV]\nS[CMDB Syncer DB]\nC[Checkmk]\nI[I-Doit]\nN[Netbox]\nR[Rest API]\nO[Other Source]\nRE[CMDB Syncer Rules]\n\n\nSD --&gt; S\nSC --&gt; S\nR --&gt; S\nO --&gt; S\n\n\nS --&gt; RE\n\nC --&gt; S \nRE --&gt; C\nN --&gt; S\nRE --&gt; N\n\nI --&gt; S\nRE --&gt; I\n\n\n</code></pre> <p>The CMDB Syncer imports all sort of devices as Hosts into his Database. Along with the Hostnames, Labels and Inventory will store as attributes. That could be an IP-Address, a Contact or every other type of Data, which fit in a key value pair like Strings or event Lists and Dicts.</p> <p>With rules, you can then add additional Attributes and Rewrite existing ones. The goal is to use this Attributes as Condition, to control the Process of export to another system.</p> <p>The Functions of the Export depend on the Other System. You will find the Details on the Module Section.</p> <p>When a Host is no longer found on an import source, it will be deleted after a grace time. Hosts no longer in this Database, will also be deleted on the export target.</p> <p>With the Command Line Interface of the Syncer, you can debug all Outcomes before you start the Sync. Some Modules like Checkmk support Web based Debug Options.</p>"},{"location":"basics/how_it_works/#architecture","title":"Architecture","text":"<p>The System is Module-based. It supports Plugins to import and export, which can use a simple API, but also ships well tested internal plugins who cover a lot.</p> <p>The Application is written in Python, the Local Database is a MongoDB. Docker is also fully supported to run it.</p> <p>The Admin Interface uses Flask-Admin. This simplifies a lot, but also limits some things in the frontend.</p>"},{"location":"basics/import/","title":"Import","text":"<p>Import is the process of query a source and transform their content to store it in the Syncer local Database. It does not matter which source this is, as long there are python modules to access it, it's just some line of code.</p> <p>When the source is not already supported out of the box, it's simply a one-time work to build the support.</p>"},{"location":"basics/install_wsgi/","title":"Installation with mod_wsgi","text":"<p>The most convenient installation of the Syncer is using Docker. There, all Dependencies can simply be satisfied. The biggest problem right now is manually installing the Python Requirements, if the Server is not connected to the Internet, and there is no local Mirror for pip. Second one is installing the MongoDB Server. For that, an extra Repository needs to be added.</p> <p>This Guide is based on a Documentation I got from a Consumer. And the plan is to adapt it to make it prefect. I would appreciate your help here.</p>"},{"location":"basics/install_wsgi/#base-requirements-for-system","title":"Base Requirements for System","text":"<p>For the Syncer to Run, you need these Dependencies: </p> <ul> <li>yum install python3.11</li> <li>yum install httpd</li> <li>yum install python3.11-mod_wsgi</li> </ul> <p>Also needed is MongoDB, but this is covered later</p>"},{"location":"basics/install_wsgi/#build-requirements-to-create-the-python-environment","title":"Build Requirements to create the Python Environment","text":"<p>The Syncer needs a Python Virutal Environment for his Modules. To Install that (see default doc) you need the following:</p> <ul> <li>yum groupinstall \"Development Tools\"</li> <li>yum install httpd-devel  </li> <li>yum install python3.11-devel</li> </ul>"},{"location":"basics/install_wsgi/#checkout-the-repo-and-create-the-environment","title":"Checkout the Repo and create the Environment","text":"<p>Best go to /var/www then follow this description</p>"},{"location":"basics/install_wsgi/#configure-apache","title":"Configure Apache","text":"<p>The Default Installation UWSGI is not working on Red Hat. But there is that even better Workaround. It works with the python3-11-mod_wsgi we installed earlier.</p> <p>Just create the following Config File in /etc/httpd/conf.d/ (May adapt the Vhost Settings if you have Checkmk Installed on the same server)</p> <pre><code>&lt;VirtualHost *&gt;\n    ServerName example.com\n    WSGIDaemonProcess cmdbsyncer python-home=/var/www/cmdbsyncer/ENV user=apache group=apache threads=5\n\n    WSGIScriptAlias / /var/www/cmdbsyncer/app.wsgi\n\n    &lt;Directory /var/www/cmdbsyncer&gt;\n        WSGIProcessGroup cmdbsyncer\n        WSGIApplicationGroup %{GLOBAL}\n        Order deny,allow\n        Allow from all\n    &lt;/Directory&gt;\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"basics/install_wsgi/#mongodb","title":"Mongodb","text":"<p>Best would be to enable a repo with MongoDB in the Subscription Manger. But you can also work with the officiall open-source one, described here:   https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-red-hat/</p> <p>The File for /etc/ym.repos.d/mongodb.repo:</p> <pre><code>[mongodb-org-7.0]\nname=MongoDB Repository\nbaseurl=https://repo.mongodb.org/yum/redhat/9/mongodb-org/7.0/x86_64/\ngpgcheck=1\nenabled=1\ngpgkey=https://pgp.mongodb.com/server-7.0.asc\n</code></pre> <p>Then you can install Mongodb yum install -y mongodb-org</p>"},{"location":"basics/install_wsgi/#final","title":"Final","text":"<p>If you get Access Denied messages in the Apache Log, you need to configure or disable SELINUX. If you configure it, I would be happy to get the info how to do that for this documentation.</p>"},{"location":"basics/lcl_config/","title":"APP Configuration","text":"<p>The application comes with some default Settings, for example to set the URL prefix or MongoDB Connection. The setting of this is important, if some links in the Backend won't work. All what's set, you will find in application/config.py, but you should not change something in this file. Instead, use the file local_config.py in the root folder. It contains at least a dictionary called config. It it not yet exists, create it with ./cmdbsycer sys self_configure  With the Keys of this Dictionary, you can overwrite every key from application/config.py, or you can add all the settings the Framework Flask has.</p> <pre><code>\"\"\"\nLocal Config\n\"\"\"\nconfig = {\n    'LOWERCASE_HOSTNAMES' : True,\n    'BASE_PREFIX' : '/cmdbsyncer/'\n}\n</code></pre>"},{"location":"basics/lcl_config/#global-config-vars","title":"Global Config Vars","text":"Name Function LOWERCASE_HOSTNAMES (bool) Force Hostnames to be Lowercase STYLE_NAV_BACKGROUND_COLOR Background Color for the Navigation Bar SYLE_NAV_LINK_COLOR Color of the Navigation Links HEADER_HINT Free String shown in the Navigation HTTP_REQUEST_TIMEOUT Timeout for HTTP Requests made by Plugins SECRET_KEY Key used to encrypt the session cookie CRYPTOGRAPHY_KEY Key used to encrypt stored passwords TIME_STAMP_FORMAT Python Formatstring for Date in log HOST_LOG_LENGTH Number of Events logged to Hosts objects CHECK_FOR_VALID_HOSTNAME Make sure that if object type is host, the hostname is valid (RFC) ADMIN_SESSION_HOURS Hours bevore logout from Admin Panel BASE_PREFIX Start part for the Url prefixed in links SESSION_COOKIE_NAME Name of the login Cookie in syncer. Important if running multiple instances LOG_LEVEL Python Log Level, numeric or logging.DEBUG LOG_CHANNEL Log Chanel, default: logging.StreamHandler() PASSWD_MIN_PASSWD_LENGTH Min Password in case of Password Change PASSWD_SPECIAL_CHARS <code>True or False</code>, Does Password needs Special Charts PASSWD_SPECIAL_DIGITS <code>True or False</code>, Does Password needs Digits PASSWD_SEPCIAL_UPPER <code>True or False</code>, Does Password needs Uppercase Chars PASSWD_SEPCIAL_LOWER <code>True or False</code>, Does Password needs Lowercase Chase PASSWD_SPECIAL_NEEDED <code>int</code> Number of neede Special Chars of all groups. REPLACE_ATTRIBUTE_KEYS Also replace Keys of Attributes with given Replacers LOWERCASE_ATTRIBUTE_KEYS Store Attributes only with Lowercase Keys LABELS_ITERATE_FIRST_LEVEL IF Attribute contains value is a dict, the first keys of the dict will get seperate attributes LABELS_IMPORT_EMPTY <code>True of False</code>, Set False to no loger import Labels which have no Value REPLACERS List of Tuples for Replacments DISABLE_SSL_ERRORS Ignore SSL Errors for HTTP Requests HTTP_REQUEST_TIMEOUT Timeout for HTTP Requests HTTP_REPEAT_TIMEOUT Timeout between the Retries HTTP_MAX_RETRIES Number of Retries on failed HTTP Requests SWAGGER_ENABLED <code>True or False</code> Disable or Enable the API Swagger for the Rest API FILEADMIN_PATH Path for the Working Folder used in the GUIs Fileadmin ADVANCED_RULE_DEBUG For Development only: If enabled all Condition Matches will print if they match or not ## Modul Specific Config <ul> <li>Checkmk Config</li> </ul>"},{"location":"basics/list_mode/","title":"List Variable Mode","text":"<p>Some Rules support the Iteration of List-based Variables. These Rules have two extra options in their outcome:</p> <p></p> <p>This function basically multiplies the Outcomes by iteration over the Attribute given in 'List Variable Name' Field. Also, you need to activate it using the Checkbox.</p> <p>In the 'Param' Field, you then use <code>LIST_VAR</code> to access the loop Variable.</p>"},{"location":"basics/list_mode/#example","title":"Example","text":"<p>Best to Understand is using an Example:</p> <p>Your host has this Varialbe:</p> <pre><code>  Variablename: [{'name': 'Harry'}, {'name': 'Hirsch'}]\n</code></pre> <p>If you then set  <pre><code>{{LIST_VAR['name']}}\n</code></pre> as Param, </p> <p>The rule will now create two more Outcomes with 'Harry' and 'Hirsch' for the used field. All other Outcome Params will be duplicated to to 'Harry' and 'Hirsch'.</p> <p>If you have more List Variables in one rule, you need to make sure that the Order of the given List Variables are always the same. Ideally, it's always the same list, but just another Dict key from it. Otherwise Data can be mixed up.</p>"},{"location":"basics/logging/","title":"Logging","text":"<p>Logging is a important function for a Application which needs to run in the Background. Therefore, the Syncer Contains multiple options you can use.</p>"},{"location":"basics/logging/#the-web-logging","title":"The Web Logging","text":"<p>Every Action creates an Entry inside the Log, which you can find in the GUI. There you find not only Metrics, but also the error on Objects you are exporting. </p> <p>Log entries, which contain an error, are also marked with a red sign.</p>"},{"location":"basics/logging/#flexible-syslog-logging","title":"Flexible Syslog Logging","text":"<p>As of v3.8.2, everything which is logged in the Weblog, and depending on the log level even more, is also logged with the logging module of python. In fact, if you use --debug the log level of this Module is set to Debug, and on your Console you see more this Detailed Output.</p> <p>You can adapt the behavior to your personal needs, by overwriting the key \"LOGGING\" from application/config.py, within your local_config.py.</p> <p>Just make sure, to not break Syncers Behavior. There always needs to by the <code>console</code>handler, and the <code>debug</code> logger. But the <code>syslog</code> handler, you can overwrite to send messages to an external Log Server. </p> <p>Some documentation you also find here</p>"},{"location":"basics/logging/#monitoring","title":"Monitoring","text":"<p>To get notified about Problems within the Syncer Processes, you can use a Checkmk Check which you find in the exchange</p>"},{"location":"basics/maintenance/","title":"Remove Hosts, or Maintenance","text":"<p>We covered now that Hosts are imported to the Syncer, and that they are exported to other systems based on rules.  But what happens, if a host is not longer part of your CMDB? For example, when it's retired.  That would mean, the Import Plugin will not find this Host any more. But only the Hosts found by the Import Plugin, will be marked as be seen:</p> <p></p> <p>It can now be configured when you want them to be deleted by the Syncer. Deleting them from Syncer, will also mean they will be deleted from the systems you export to, example from Checkmk.</p> <p>The recommended way is to use the Cron Feature and set a Cronjob to do that. For that, create an Account, set it to Mode \"Maintenance\" and use that as configuration. There you can set after how many Days you want to delete, and you can filter from which source only you would like to delete.</p> <p>There you can also set an account filter, or configure a threshold on which the syncer won't delete any objects from the db.</p> <p></p> <p>From Command line without the Cron Feature, use:</p> <pre>\n/cmdbsyncer sys maintenanc DAYS\n</pre> <p>To remove after days or refer to your account with --account</p>"},{"location":"basics/rewrite_attributes/","title":"Rewrite Attributes","text":"<p>Different targets have different needs in how the name of an attribute have to be. Specially if you want to control Ansible our set custom Checkmk Attributes.</p> <p>To cover that, you can rewrite Attributes for every Module. </p> <p></p> <p>So for example if you import an attribute like the ipaddress from a CSV, there will be an prefix like csv_ipaddress. With this rule you could rename it to just ip_address.</p>"},{"location":"basics/rewrite_attributes/#operations","title":"Operations","text":""},{"location":"basics/rewrite_attributes/#for-attribute-names","title":"For Attribute Names","text":"Function Description <code>Don't Use</code> Just set Old Attribute Name, it will create a new Attribute out of it <code>Overwrite with fixed String</code> String set in 'New Attribute Name' will overwrite the one given in 'Old Attribute Name' <code>Overwrite with Jinja Template</code> Attribute Name is built with Jinja, you can use all of the Hosts Attribute or {{HOSTNAME}} <code>Convert List of Strings</code> See Description below"},{"location":"basics/rewrite_attributes/#convert-list-of-string","title":"Convert List of String","text":"<p>This function can create multiple new Attributes, out of a list either in a other Attribute or build using Jinja.</p> <p></p> <p>To set it up, enter in \"Old Attribute Name\" the Attribute you get the information from. The Content of this attribute can be used as {{result}} in the Field \"New Attribute Name\". If the Content is already a list like: <pre><code>['one_service', 'another_service']\n</code></pre> you are good to go. If not, use Jinja to archive that outcome.</p> <p>An Example for a prefix would look like this: <pre><code>[{% for label in get_list(result)%} 'my_prefix/{{label}}',{%endfor%}]\n</code></pre> Please note, that Jinja is used, to build a String, looking like a list again. Therefore the Brackets around and the ticks with the comma.</p> <p>Now just set for the Value for example the Operation \"To String\" and the \"New Value\" to yes.</p> <p>Now you will get tow Attributes: - one_serive: yes - another_service: yes</p>"},{"location":"basics/rewrite_attributes/#for-attribute-values","title":"For Attribute Values","text":"Function Description <code>To String</code> Overwrite the new or old Attribute with a fixed String <code>With Split</code> Use performant Python Split to rewrite value, see description below <code>With Jinja Template</code> User Jinja with all the hosts Attributes to rewrite the value"},{"location":"basics/rewrite_attributes/#split","title":"Split","text":"<p>Add a pattern to the field. This Pattern contains a seperator where you want to split the string, and then the index for the result.</p> <p>Example: <pre><code>/:0\n</code></pre></p> <p>Split example 127.0.0.1/24: The String would split at /, result would ['127.0.0.1', '24'] From there it would pick the first (0) index, new value would be: 127.0.0.1</p>"},{"location":"basics/rewrite_attributes/#create-a-new-attribute","title":"Create a New Attribute","text":"<p>If you specify a not existing attribute as \"old_attribute_name\", it will be created as a new Attribute. Of course, all Overwrite Options can be used for the value, so you could create a new attribute which contains the value of multiple other attributes.</p>"},{"location":"basics/rewrite_hostnames/","title":"Rewrite Hostnames","text":"<p>The renaming of Hostnames must happen on import. For most of the integrated plugins, you can do that using the Jinja2 Template language. This works since version 3.4. For that, an Account has to be set for your import. If you save that account, a Custom Attribute 'rewrite_hostname' will appear.</p>"},{"location":"basics/rewrite_hostnames/#example","title":"Example","text":"<p>Would the host have an Attribute dns, a rewrite could look like this:</p> <pre>\n{{HOSTNAME}}.{{dns}}\n</pre> <p></p> <p>Note that HOSTNAME is the internal variable for the current hostname, and dns can the exact name of the attribute the has.</p> <p>If you change that setting later, make sure to remove the hosts with the not longer matching hostnames. Because for Syncer, a Host after rewrite will be a completely new object.</p>"},{"location":"basics/setup_code/","title":"Installation from Code","text":"<p>The most common way to use the application without Docker is direct from Code. This is easy if the server has an Internet Connections. Updates are easy as git pull then.</p>"},{"location":"basics/setup_code/#steps","title":"Steps","text":"<p>If you not using docker, that are the steps to make the syncer run: <pre><code>graph LR\n\nA[Download Repo] --&gt; B[Create Python Environment] --&gt; C[Install Python Requirements] --&gt; D[Setup Mongodb] --&gt; E[Setup Apache with UWsgi]</code></pre></p>"},{"location":"basics/setup_code/#download-repo","title":"Download Repo","text":"<p>You need to check out the Code directly from GitHub.  Go to the Repo, and copy the Clone URL to example /var/www. In all examples, this Path is used.</p> <p>Repo</p> <p></p> <p>Example: <pre><code>cd /var/www\ngit clone https://github.com/kuhn-ruess/cmdbsyncer\ncd cmdbsyncer\n</code></pre></p>"},{"location":"basics/setup_code/#install-pythons-virtual-environment","title":"Install Pythons Virtual Environment.","text":"<p>The Syncer Need some Python Libraries. But these we don't want to install into your system. Instead, we create a virtual environment. Make sure that you have at least python3.10. The Python Interpreter on your system may have a different Name.</p> <p>Always Make sure you are in /var/www/cmdbsyncer</p> <p><code>python3.11 -m venv ENV</code></p> <p>This Environment needs to be loaded from now on, every time something is done with the syncer, also for every Cronjob which you will run.</p> <p><code>source ENV/bin/activate</code></p> <p>To this Environment, you install the Python Libraries. This is done with just one command:</p> <p><code>pip install -r requirements.txt</code></p> <p>In Case, you plan to use Ansible, also import the Ansible requirements:</p> <p><code>pip install -r requirements-ansible.txt</code></p> <p>Extra Database stuff you find in requirements-extras.txt</p>"},{"location":"basics/setup_code/#install-mongodb-server","title":"Install Mongodb Server","text":"<p>The Syncer needs the Mongodb. All you need to do is to install it, with your Packet Manager. Then you are ready to go.</p>"},{"location":"basics/setup_code/#configure-defaults","title":"Configure Defaults","text":"<p>When the Database is running, run </p> <pre><code>./cmdbsyncer sys self_configure\n</code></pre> <p>This Should also run after you Update the Syncer</p>"},{"location":"basics/setup_code/#the-web-interface","title":"The Web Interface","text":"<p>To take a brief look, you can start the development Server:</p> <p><code>flask run --host 0.0.0.0 --port 8080</code></p> <p>But then you should Setup UWSGI. There is an Example with UWSGI and Apache, but it's even easier with NGINX. Or go with this simpler one, using mod_wsgi and Apache</p>"},{"location":"basics/setup_code/#first-steps","title":"First Steps","text":"<p>Make the First Steps</p>"},{"location":"basics/setup_docker/","title":"Docker","text":"<p>The Project is not in the Docker Library yet, but you can run it after Checkout the Code.</p> <p>The Docker Compose File there contains all the needed dependencies. The Dockerfile you found already in the Main Directory of the repo, I guess.</p> <p>And if you develop with the syncer, you may want to look into the ./helper command, which provides you an environment with live refresh after code changes.</p>"},{"location":"basics/setup_docker/#docker-behind-proxy","title":"Docker behind proxy","text":"<p>If you plan to use Docker behind a proxy, then you have to possibilities to get it running.</p>"},{"location":"basics/setup_docker/#modify-docker-composelocalyml","title":"Modify docker-compose.local.yml","text":"<p>Currently, we do not add proxy settings and provide following setup: <pre><code>api:\n    build:\n      dockerfile: Dockerfile.local\n    environment:\n      config: compose\n      FLASK_DEBUG: 1\n    ports:\n      - 5003:5003\n    volumes:\n      - ./:/srv\n</code></pre></p> <p>You can add your proxy configuration like this: <pre><code>  api:\n    build:\n      dockerfile: Dockerfile.local\n    args:\n      HTTPS_PROXY: PROTOCOL://SERVERNAME:PORT\n    environment:\n      config: compose\n      FLASK_DEBUG: 1\n    ports:\n      - 5003:5003\n    volumes:\n      - ./:/srv\n</code></pre></p>"},{"location":"basics/setup_docker/#add-proxy-to-user-environment","title":"Add proxy to user environment","text":"<p>If you want to add the proxy for the user, which is used for Docker, then you can add it directly to his environment. Please use <code>~/.docker/config.json</code>: <pre><code>{\n  \"proxies\": {\n    \"default\": {\n      \"httpProxy\": \"PROTOCOL://SERVERNAME:PORT\",\n      \"httpsProxy\": \"PROTOCOL://SERVERNAME:PORT\",\n      \"noProxy\": \"EXCLUDE1,EXCLUDE2,127.0.0.0/8\"\n    }\n  }\n}\n</code></pre></p>"},{"location":"basics/setup_docker/#things-to-consider","title":"Things to Consider","text":""},{"location":"basics/setup_docker/#mongodb","title":"MongoDB","text":"<p>The Project always needs his MongoDB, like the docker-compose.yml also defines. </p>"},{"location":"basics/setup_docker/#access-to-the-container","title":"Access to the container","text":"<p>To work with the Project, not all can be done in the Web interface. For example, for Debug and Testing, the Access to the Shell is needed. </p>"},{"location":"basics/setup_docker/#cron-jobs","title":"Cron Jobs","text":"<p>The Syncer Needs Cron Jobs. These need to be triggered using the docker exec command</p>"},{"location":"basics/setup_docker/#csv-files","title":"CSV Files","text":"<p>If you want to import CSV Files into the Syncer, make sure to define a Volume where you can place it.</p>"},{"location":"basics/setup_docker/#resources","title":"Resources","text":"<p>The Syncer does not need many Resources, mainly Disk Space. And at least two CPUs. But if you have many rules, you will benefit from more CPUs since the Syncer uses for Calculations Multiprocessing all available cores. </p>"},{"location":"basics/setup_docker/#uwsgi-nginx","title":"UWSGI/ NGINX","text":"<p>Inside the Container you will find a Python Application. Normally, they are accessed using UWSGI. And many Containers then also contain an NGINX in Front of this UWSGI.  The CMDB Syncer Container has no Nginx, since it would be redundant. Most likely, the Reverse proxy in Front of the Container will be a Nginx anyway. And so, your Reverse Proxy can speak directly UWSGI with the Container on the exposed port.</p>"},{"location":"basics/updates/","title":"Update CMDB Syncer","text":"<p>As of now, if you want to Update the CMDB Syncer, just pull it from git agin</p> <pre><code>cd /var/www/cmdbsyncer\ngit pull\n</code></pre> <p>If using docker, now rebuild your image and restart.</p> <p>If you have the UWSGI based installation, just reload uwsgi.</p> <pre><code>service uwsgi reload\n</code></pre> <p>Warning: Always check Changelog before you Update: Changelog</p> <p>The run:</p> <pre><code>./cmdbsyncer sys self_configure\n</code></pre>"},{"location":"basics/updates/#problems","title":"Problems","text":"<p>Sometimes the Application will not start up. In these cases, check the UWSGI Logs in /var/log. It depends on which files your Distribution will log.</p> <p>It's likely, then that a Module has changed. You can update the Modules easily:</p> <pre><code>cd /var/www/cmdbsyncer\nsource ENV/bin/activate\npip install -r requirements.txt\n</code></pre> <p>If you use Docker, you should not run n any problems. </p>"},{"location":"basics/uwsgi_apache/","title":"How to Setup for Production using UWSGI and Apache","text":"<p>Take Care: This Documentation descripes the use with NGINX and UWSGI and I use this Setup normally for my APIs with a lot of traffic. But for the Syncer that could be a bit to much overhead. You can refer to here to see a way, where you can use apache with mod-wsgi which is a simpler way, since you don't need to run the extra uwsgi deamon. That means you can scipp the uwsgi part here then. </p>"},{"location":"basics/uwsgi_apache/#requirements","title":"Requirements","text":"<ul> <li>Python Version &gt;= 3.11 must be installed</li> <li>MongoDB Server must be Installed</li> <li>Apache Mod UWSGI must be Installed and activated</li> <li>uWSGI and the python3 Plugin of uWSGI must be installed in version at least 3.9</li> </ul>"},{"location":"basics/uwsgi_apache/#first-steps","title":"First Steps:","text":"<p>Checkout the Code into /var/www/cmdbsyncer. We will define a Path in Apache which will be proxy to the uWSGI daemon. For this Example: /cmdbsyncer Update/ Create a local_config and adjust the BASE_PREFIX to that path. For example, https://checkmk-server.de/cmdbsyncer would be 'BASE_PREFIX': '/cmdbsyncer/'. You find here how to do that.</p>"},{"location":"basics/uwsgi_apache/#setup-uwsgi","title":"Setup uWSGI","text":"<p>In ./deploy_configs you will find the example_apache/ Folder. Use the uwsgi-config.ini and copy it to /etc/uwsgi.d/ or depending on your Linux Distribution, to the Folder for the config files. You should rename the file like cmdbsyncer.ini If you used different Paths, you need to update them the ini file.</p> <p>Please note that in the uwsgi-config.py you find a plugin = python3. This has maybe a different Name on your OS. You could need for example python311</p> <p>Restart UWSGI with service uwsgi restart.</p>"},{"location":"basics/uwsgi_apache/#setup-apache","title":"Setup Apache","text":"<p>Also in the example_apache folder, there is an apache_config.conf. Copy it, depending on your Linux Distribution, to /etc/apache2/conf.d, /etc/httpd/conf.d or so on.  In this file, you can change the Path for the Application. Make sure to adjust the BASE_PREFIX as described before in case of changes. Also rename it as you need and Restart Apache.</p>"},{"location":"basics/uwsgi_apache/#final","title":"Final","text":"<p>If you left all examples as they are, it would be http[s]://servername/cmdbsyncer/admin where you can access the Frontend</p>"},{"location":"basics/uwsgi_apache/#known-problems","title":"Known Problems","text":""},{"location":"basics/uwsgi_apache/#uwsgi-python-version-to-old-on-redhat-or-centos","title":"uWSGI Python Version to old on Redhat or Centos","text":"<p>For Redhat, best use the solution descripted here, but if you want to go the way do this:</p> <ul> <li>yum -y install gcc libcap-devel libuuid-devel make openssl-devel python311-devel pcre-devel uwsgi-devel</li> <li>if needed: yum install rpm-config (if redhat-hardened missing)</li> <li>cd /usr/src/uwsgi/NUMMER</li> <li>PYTHON=python3.11 /usr/sbin/uwsgi --build-plugin \"plugins/python python311\"</li> <li>cp plugin to /usr/lib64/uwsgi</li> </ul>"},{"location":"basics/uwsgi_apache/#filesocket-no-right-for-apache","title":"Filesocket no right for Apache:","text":"<ul> <li>Add Apache user to uwsgi group</li> <li>Disable SELinux</li> </ul>"},{"location":"checkmk/","title":"Checkmk","text":"<p>The Checkmk Module of Syncer overtakes Automation for Functions in Checkmk. Based on your Hosts and their Attributes, you control how to sync your Hosts to Checkmk, and sort them in automatically created folders.</p> <p>Furthermore, you can create Contact-, Host-, Service Groups based on Attributes, all types of rules or control the Bake and Sign of Agents or the Activate Changes from your Command line.</p> <p>See the Recipes Section for more Step by Step docs.</p>"},{"location":"checkmk/#labels","title":"Labels","text":"<p>When the Syncer takes over, you should no longer set manual labels directly to hosts in Checkmk anymore. If you still need to do that, which is not recommended, you can work with prefixes to solve this.  But better if all direct labels could come from the Syncer.  Direct Labels means, the ones directly with the Host. Not the ones that are set via Checkmk Rule, or the ones that are discovered or set on folders. These you can still use in any case.</p> <p>Inside the Syncer you will find many attributes and you can create Custom Attributes or Rewriten them. But as of default, none of them will be exported to Checkmk as a label. To export them, you need to whitelist them in Checkmk -&gt; Filter. The Only exception are labels starting with cmdbsyncer/. These are internal labels for helper functions the syncer uses to optimize, e.g Checkmk rule creation.</p>"},{"location":"checkmk/accounts/","title":"Checkmk Account Settings","text":"<p>The Following Extra Configuration is possible for Checkmk Accounts</p> Field Description <code>limit_by_accounts</code> Comma seperated list of Account names to only export hosts with matching account <code>limit_by_hostnames</code> Comma seperated list of Hosts to Export <code>list_disabled_hosts</code> Print a list of Hosts at the end of the export proccess <code>dont_delete_hosts_if_more_then</code> Do not delete any host, if the total number of hosts to delete is higher then the given number <code>dont_activate_changes_if_more_then</code> Do not activate changes if the used user created more then the given number of changes <code>import_filter</code> Simple Filter: Hosts starting with string are not imported (Comma seperation of multiple strings possible)"},{"location":"checkmk/bake_sign/","title":"Bake and Sign Agents","text":"<p>In some cases, you may want to automate the Bake and Sign of the Checkmk Agents in the Bakery. This could be after you crated them via the RestAPI, or also when they are discovered via the Network scan.</p> <p>As usual, you can use the Command Line Option to do that:</p> <p><code>./cmdbsyncer checkmk bake_and_sign_agents ACCOUNTNAME</code></p> <p>or you just configure it as job inside the cron manger.</p>"},{"location":"checkmk/bake_sign/#requirements","title":"Requirements","text":"<p>You need to configure the Agent Signing ID and Password inside the Account settings of the CMDBsyncer. The Key ID you find on the Page with Signing keys directlyin Checkmk.</p> <p>In the Account, you need to set the Fieldnames like this:</p> <ul> <li>bakery_key_id</li> <li>bakery_passphrase</li> </ul> <p>If these Keys do not exist already as custom_fields, just create them. With Syncer Version 3.9 just save the Account once, to automatically create them.</p>"},{"location":"checkmk/bi/","title":"Checkmk Business Intelligence","text":"<p>Checkmks BI Feature can fully be automated by these Rules. To Set-up the Config, just create One example in Checkmk, then Fetch it with the API. Place the JSON Response into the Syncer, and there you can replace where needed with Jinja.</p> <p>Checkout: Modules \u2192Checkmk \u2192Manage Business Intelligence </p>"},{"location":"checkmk/bi/#bi-aggregations","title":"BI Aggregations","text":"<p>In the Interactive API GUI of Checkmk, look for GET /objects/bi_aggregation/{aggregation_id} An Example would look like:</p> <p><pre><code>{\n  \"pack_id\": \"default\",\n  \"id\": \"default_aggregation\",\n  \"comment\": \"\",\n  \"customer\": null,\n  \"groups\": {\n    \"names\": [\n      \"Hosts\"\n    ],\n    \"paths\": []\n  },\n  \"node\": {\n    \"search\": {\n      \"type\": \"host_search\",\n      \"conditions\": {\n        \"host_folder\": \"\",\n        \"host_label_groups\": [],\n        \"host_tags\": {\n          \"tcp\": \"tcp\"\n        },\n        \"host_choice\": {\n          \"type\": \"all_hosts\"\n        }\n      },\n      \"refer_to\": {\n        \"type\": \"host\"\n      }\n    },\n    \"action\": {\n      \"type\": \"call_a_rule\",\n      \"rule_id\": \"host\",\n      \"params\": {\n        \"arguments\": [\n          \"$HOSTNAME$\"\n        ]\n      }\n    }\n  },\n  \"aggregation_visualization\": {\n    \"ignore_rule_styles\": false,\n    \"layout_id\": \"builtin_default\",\n    \"line_style\": \"round\"\n  },\n  \"computation_options\": {\n    \"disabled\": true,\n    \"use_hard_states\": false,\n    \"escalate_downtimes_as_warn\": false,\n    \"freeze_aggregations\": false\n  }\n}\n</code></pre> Set this now as Rule Template, and replace needed parts with attributes you have from Hosts or Objects. Full Flexibility of Jinja is Available. </p>"},{"location":"checkmk/bi/#bi-rules","title":"BI Rules","text":"<p>In the Interactive GUI, look for GET /objects/bi_rule/{rule_id}</p> <p>The Example her: <pre><code>{\n  \"pack_id\": \"default\",\n  \"id\": \"filesystem\",\n  \"nodes\": [\n    {\n      \"search\": {\n        \"type\": \"empty\"\n      },\n      \"action\": {\n        \"type\": \"state_of_service\",\n        \"host_regex\": \"$HOSTNAME$\",\n        \"service_regex\": \"fs_$FS$$\"\n      }\n    },\n    {\n      \"search\": {\n        \"type\": \"empty\"\n      },\n      \"action\": {\n        \"type\": \"state_of_service\",\n        \"host_regex\": \"$HOSTNAME$\",\n        \"service_regex\": \"Filesystem$FS$$\"\n      }\n    },\n    {\n      \"search\": {\n        \"type\": \"empty\"\n      },\n      \"action\": {\n        \"type\": \"state_of_service\",\n        \"host_regex\": \"$HOSTNAME$\",\n        \"service_regex\": \"Mount options of $FS$$\"\n      }\n    }\n  ],\n  \"params\": {\n    \"arguments\": [\n      \"HOSTNAME\",\n      \"FS\"\n    ]\n  },\n  \"node_visualization\": {\n    \"type\": \"none\",\n    \"style_config\": {}\n  },\n  \"properties\": {\n    \"title\": \"$FS$\",\n    \"comment\": \"\",\n    \"docu_url\": \"\",\n    \"icon\": \"\",\n    \"state_messages\": {}\n  },\n  \"aggregation_function\": {\n    \"type\": \"worst\",\n    \"count\": 1,\n    \"restrict_state\": 2\n  },\n  \"computation_options\": {\n    \"disabled\": false\n  }\n}\n</code></pre></p> <p>As before, add this to the Rule Template and replace with Jinja.</p>"},{"location":"checkmk/bi/#export-on-command-line","title":"Export on Command Line","text":"<p>If you now wan't to export the rules, use</p> <p>./cmdbsyner checkmk export_bi_aggregations ACCOUNT AND: ./cmdbsyncer checkmk export_bi_rules ACCOUNT</p>"},{"location":"checkmk/big_environments/","title":"Big Environments","text":"<p>The Syncer is also capable to managing big (&gt;100k hosts) Checkmk Environments.  For that, config switches exist, which you can enable in case e.g. Checkmk runs in timeouts when the API is queried.</p> <p>All of them, you can set in you local_config.py</p> Variable Funtion CMK_COLLECT_BULK_OPERATIONS When Request to Checkmk take too long, the DB Cursor can run in a Timeout. With that switch, DB and CMK Operationswill be seperated. Needs more RAM. CMK_GET_HOST_BY_FOLDER Query Hosts from Checkmk Folder by Folder  That prevents too big a request for hosts  which will end in a timeout in CMK."},{"location":"checkmk/big_environments/#limiting-objects","title":"Limiting objects","text":"<p>It's likely that you have different types of objects in the Syncer Database. In order that the Syncer does not need to calculate on objects not relevant for an operation, it's possible to limit the objects which will be used. That happens directly at Database level, so way faster than just using the normal Filter.</p> <p>To set this up, switch to the Account for the Operation,  add a Plugin Setting, Select the Operation on which you want to use it, and the objects you would like to use it on.</p>"},{"location":"checkmk/cmk_attributes/","title":"Set all Kinds of Attributes to Checkmk","text":"<p>If you'd like to, you can set a rule to convert Syncer Attributes into Checkmk Attributes, or even just create your Custom ones using Placeholders. Only the Name needs to match the required Checkmk Name. To make that sure for existing Attributes, you can rewrite them using a rule in CMK \u2192 Rewrite Attributes. </p> <p>The Easy way to find out this Attribute's Name, is to check with the Swagger Documentation provided in Checkmk.</p> <p>It's also possible to set Host Tags this way, because a Host Tag is nothing other then a Attribute in Checkmk.</p> <p>Let's do some Examples. The Rule for everything is Checkmk \u2192 CMK Export Rules.</p>"},{"location":"checkmk/cmk_attributes/#where-to-find-the-attribute-name-for-checkmk","title":"Where to find the Attribute Name for Checkmk","text":"<p>If you don't know the name already, just set a Host manually with this attribute and query it using Swagger Documentation. Here is an Example how to do that:</p> <p>Open Swagger: </p> <p>Find and Test Endpoint:</p> <p></p>"},{"location":"checkmk/cmk_attributes/#how-to-unset-an-attribute","title":"How to Unset an Attribute","text":"<p>If the Value of an Attribute is <code>None</code> or <code>False</code>, the Syncer automatically removes the Attribute in Checkmk. But the syncer will not remove attributes, if it's just disappeared in his Database. The Reason for that is because in Checkmk every user can also set attribute.  Therefore, the Syncer would not know whether this was an Attribute set by him or not. </p>"},{"location":"checkmk/cmk_attributes/#examples","title":"Examples","text":""},{"location":"checkmk/cmk_attributes/#setting-an-ip-address-attribute","title":"Setting an IP Address Attribute","text":"<p>To use an existing Syncer Attribute, which either already have the correct name ipaddress, or is rewritten to this name, use the \"Create Checkmk-Attribute\" Action like this:</p> <p></p> <p>In the Checkmk API, it would look like this: </p>"},{"location":"checkmk/cmk_attributes/#setting-management-boards-as-attributes","title":"Setting Management Boards as Attributes","text":"<p>For this, you can create Custom Attributes. If for example all your physical hosts, have a DNS name for the Management Board which contains the actual Hostname, you can do it like this:</p> <p> Here the Hostname could be srvlx100, the management Board rib-srvlx100.</p> <p>In addition, please note the Second Outcome, since the Management Boards require at least to settings.</p> <p>And here how to find this example in the CMK API: </p>"},{"location":"checkmk/cmk_attributes/#setting-nested-attributes-like-snmp-community","title":"Setting nested attributes like SNMP Community.","text":"<p>Sometimes you will see that attributes you want to set are in the form of a Dictionary, example the SNMP Community:</p> <pre><code>\"snmp_community\": {  \n    \"type\": \"v1_v2_community\",  \n    \"community\": \"public\"  \n}\n</code></pre> <p>Good news, the Syncer can detect that format to, converts it and will send it to Checkmk. Just set it like this as a custom Checkmk Attribute</p> <pre><code>snmp_community:{\n\"type\": \"v1_v2_community\",\n\"community\": \"public\"\n}\n</code></pre> <p>Please note that for the Key Name, no Ticks are used.</p>"},{"location":"checkmk/commandline/","title":"Commandline Options","text":"<p>The Checkmk System has the following Command Line Options. You can access them with ./cmdbsyncer checkmk</p> Parameter Description debug_host Show all Matching Rules and Variable Outcomes export_hosts Send Hosts to Given Checkmk Instance export_groups Create Checkmk Groups (based on your rules) export_rules Export your Checkmk rules to the Checkmk Instance activate_changes Activate Checkmk Changes on given Instance bake_and_sign_agents Bake the Agents in given Instance, You have to set bakery_key_id and bakery_passphrase as Custom Account Settings show_hosts Just print out all Host which would be exported to Checkmk inventorize_hosts Run Inventory for attributes, used mainly for Ansible export_bi_aggregations Export Checkmk BI Aggregation Rules export_bi_rules Export Checkmk BI Rules export_downtimes Export Downtimes to Checkmk export_tags Export Tag Group Config to Checkmk export_users Export/ Manage Users in Checkmk import_v1 Import Hosts from Checkmk 1.x import_v2 Import Hosts from Checkmk 2.x show_hosts Print all Hosts which would be exported to Checkmk show_labels List all Labels which later will exist in Checmk show_missing_hosts Show Hosts which are in Checkmk, but not in Syncer"},{"location":"checkmk/config_vars/","title":"Config Variables","text":"<p>List of config Variables which can be overwritten in local_config.py</p> Variable Description CMK_BULK_CREATE_HOSTS Default True: Bulk Create Hosts CMK_BULK_CREATE_OPERATIONS How many objects for each bulk request CMK_BULK_DELETE_HOSTS Default: True: Bulk Delete Host CMK_BULK_DELETE_OPERATIONS How many objects for each bulk request CMK_BULK_UPDATE_HOSTS Default True: Bulk Update Hosts CMK_BULK_UPDATE_OPERATIONS How many objects for each bulk request CMK_DONT_DELETE_HOSTS Disable Deletion of hosts when syncing CMK_LOWERCASE_FOLDERNAMES Default: True, Folder names are lowercase CMK_COLLECT_BULK_OPERATIONS Default: False, Do bulk operations at the end CMK_GET_HOST_BY_FOLDER Default: False: Query Hosts by Folder, not with one call. CMK_DETAILED_LOG Log for every Host the Attribute Changes done CMK_JINJA_USE_REPLACERS Default: False, Configured Replacers are used for TAG Cleanup Jinja Functions CMK_JINJA_USE_REPLACERS_FOR_HOSTNAMES Default: False, Configured Replacers are used for Hostname Cleanup Jinja Function"},{"location":"checkmk/create_cluster/","title":"Create Clusters in Checkmk","text":"<p>With the Create Cluster Rule Outcome (See Export Rules) its possible to create Checkmk Cluster Hosts instead of Normal Hosts.</p> <p>Since these Nodes have to exist in Checkmk, clusters will always create add the end of the export. But besides that, they act as normal Hosts and will honour all the configured other Settings in the Syncer.</p> <p>The difference is, that a Cluster Host needs to have a List of Nodes assigned. This Information needs to come in the Form of Attributes. You get Attributes from your CMDB, or you can add them using the CSV Features.</p> <p>You can then directly specify the Name of this Attributes in the rule, and you have the possibility to add a Wildcard add the end of an entry, to match all attributes starting with this name.</p> <p>Multiple Attributes can be comma separated, and you can also mix Wildcard and not Wildcards.</p> <p>An Example Rule can look like this:</p> <p></p> <p>In fact, this is all extra information to know, since everything else works like the Other rules. So, no special export command is used. </p>"},{"location":"checkmk/create_downtimes/","title":"Downtimes","text":"<p>Using the known Syncer Rules and the Hosts Attributes, you can create Flexible Downtimes, which can be manged in your CMDB, but then created in Checkmk by the CMDB Syncer.</p>"},{"location":"checkmk/create_downtimes/#how-to-configure","title":"How to configure","text":"<p>Modules \u2192 Checkmk \u2192 Manage Downtimes</p> Field Description Start Day Select the Day for the Downtime in the List Start Day Template Set the day, by Jinja Template. English, short  mon, tue, wed, thu, fri, sat, sun Every Select how often to repeat, eg. every 2nd Start Day Every Template Set repeat by Jinja Template. Results:  day, workday, week, 1-5 or 1.-5. Offset Days Offset in Days from the Startday Offset Template Offset in Days from Jinja Template Start Time H Start Hour (Jinja, 24h) Start Time M End Minutes (Jinja) End Time H End Hour (Jinja 24h) End Time M End Minutes (Jinja) Downtime Comment Comment for Downtime (Jina) Duration Start Flexible Downtime (Jinja)"},{"location":"checkmk/create_downtimes/#create-downtime-for-single-day","title":"Create Downtime for Single Day","text":"<p>Instead of having the Downtime Data in your CMDB and just syncing it to Checkmk, you can also set a Downtime for every given day, when a condition for a host is fulfilled. Since Version 3.9 you can set:</p> <p>Start Day: <code>Today</code> Every: <code>once</code></p>"},{"location":"checkmk/create_downtimes/#timezones","title":"Timezones","text":"<p>Downtimes in Checkmk need to be Timezone aware. The Downtimes you enter the gui, will have the Timezone of the Server/ Docker Container where you installed the syncer. But for the Downtime used in Checkmk, you need to overwrite maybe with the local_config.py.</p> <p>Example local_config.py: <pre><code>import datetime\nconfig = {\n    'TIMEZONE': datetime.timezone.utc,\n}\n</code></pre></p>"},{"location":"checkmk/create_hosttags/","title":"Hosttags","text":"<p>You can use the Syncer to manage given Host tags groups.  This means, you can use the Attributes of your Hosts, to add and remove the predefined Tags.</p> <p>Just keep in mind, that the Syncer can't remove Hostags which are still in use by rules.  In such cases, it will just no longer update the group, but not throw an exception. Just a silent error is shown.</p> <p>This feature is also using Syncer Host-Based caching to speed up even the extraction of Data and rewrites from over 100,000 Hosts. The cache is auto-refreshed if the Host changes.</p>"},{"location":"checkmk/create_hosttags/#how-to-configure","title":"How to configure","text":"<p>Go to:</p> <p>Modules\u2192 Checkmk \u2192 Manage Hosttags</p> <p>Create a new entry.</p> Field Description Group Topic Name The Category used for the Group in Checkmk Group Title The Human Readable Title of the Group, Example: My Locations Group ID The internal ID of the group. Example my_locations Group Help Help text for the User Group Multiply by List Create a set of multiple Groups, based on a list. See docu below Group Multiply List Syncer Attribute containing a list, use get_list(), See docu below Filter by Account Should the Syncer create the Tags based on Attributes only from objects managed by given Account Name Rewrite ID Jinja rewrite for the internal ID of tag. Example: {{name|lower()}} Rewrite Title Jinja rewrite the Human Readable Name of Tag Example: {{HOSTNAME|capitalize()}} Enabled Enables the Rule <p>Note 1: that {{ HOSTNAME }} is replaced by the Hostname. You can use every Host attribute here. Also, the Rewrite Fields support custom Syncer Functions.</p> <p>Note 2: To the rewrite_id field, the cmk_cleanup_tag_id() function is applied automaticly. This is important to know, if you wan't to set tags. Make sure to use that Jinja Function.</p>"},{"location":"checkmk/create_hosttags/#group-multiply-by-list","title":"Group Multiply by List","text":"<p>If you use this mode, the Syncer will create multiple groups which can't be rewritten and are based fully on the outcome of a list. In This case, you must use {{name}} as Placeholder for Topic Name and Title. In Group Multiply by List, you need to provide a Python list. This is archived with the get_list helper.</p> <p>Example: <pre><code>{{YOUR_LIST_ATTRIBUTE|safe}} # real list from attributes\n{{get_list(['Name1', 'Name2', \"Name3'])|safe}} # String given by you\n</code></pre></p> <p>Make sure to use |safe otherwise the System will escape that list</p>"},{"location":"checkmk/dcd_rules/","title":"DCD Rules","text":"<p>Starting with Checkmk 2.3, you can export DCD Rules to Checkmk. But compared to the Other Checkmk API Endpoints, the DCD Endpoint is still a bit limited. So the export in this Case is not a Sync as in other Modules, but can Create and Delete Rules.</p> <p>Go to: Modules \u2192Checkmk \u2192Manage DCD Rules</p> <p>The Rules work the same way as the other Syncer Rules do. You can create DCD Rules, with the Outcomes, and use Jinja Template Power in almost every Field.</p> <p>The Options 1 to 1 reflect the options, like you would set up a DCD Rule directly in Checkmk</p>"},{"location":"checkmk/dcd_rules/#command-line","title":"Command Line","text":"<p>To Export the DCD Rules using the CLI, use the following Command:</p> <p>./cmdbsyncer checkmk export_dcd_rules ACCOUT</p>"},{"location":"checkmk/export_rules/","title":"Set Folder and Host Attributes","text":"<p>This Rules manage how hosts will export to Checkmk. So, you can control in which Folder they will import and which attribute they will have. Note that the best way for folders is, to extract them from your Attributes.  Rules, who define Folders, are automatically stacked and result in a folder structure like /this/is/my/folder out of all the outcomes.  It makes no difference if just one rule defines multiple outcomes, or multiple rule just define one outcome. At the End, it's just a long list of outcomes in the Order given by the Sort Field. It's recommended to make use of the last_match Option in Rules, to create the wanted Folder Paths. </p> <p>The Rules you can find in: Modules \u2192 Checkmk \u2192 Set Folder and Attributes of Host</p> <p>Here you find their options explained:</p> Function Description Move to Folder Hardcode a custom Folder Name in action_param field.  You can use Jinja Attributes to build multiple Folder Levels. If a Variable not match, the rule will be ignored. Folder by Attribute Name Pick Attribute by Value and use Key as Foldername Pool Folder Matching Host will use a Pool Folder. If not action_param is given, the system will query from all folders.Otherwise you can provide a comma seperated list of Folder Pool Names.For more Details, please refer to the Folder Pool Documentation. CMK Atribute by Syncer Attribute The given Attribute Name will be sent as Checkmk Attribute.This way you can set every Attribute you wantlike ipaddress of management board.Please refer to the documentation in Recipes. Custom CMK Attributes You can specify a new Attribute as key value pair,separated by double point. You can use {{HOSTNAME}} as placeholder to create for example:managmentboard:rib-{{HOSTNAME}} as new attribute.  Return Multiple Attributes, seperated by two pipes, Example: ||  Usefull for for-loops.Find out more here. Remove given Attribute if not assigned Comma seperated list of checkmk attributes (like tags) which will be removed if not be set by another Syncer Rule Cluster The Matching Host will be created as a Cluster in Checkmk.Since Cluster have Nodes, you needto tell syncer in witch attribute he will findtheir Names. You can add the Attributes comma seperated, and use * as Wildcard add the end of the Name. See also the Documentation. Parents Set parent, Jinja Support Move Optout Matching Host will never be moved after intial creation Update Optout Attributes of Matching Host will never be  Update after inital creation Prefix Labels Every label exported gets the configured prefix Create Optout Host will not be created in Checkmk, but if found update his attributes Update only Prefixed Labels Syncer will only change labels, which have the given prefix Dont update prefixed Labels Do not touch Labels with given prefix"},{"location":"checkmk/export_rules/#set-custom-folder-attributes","title":"Set Custom Folder Attributes","text":"<p>The Syncer will Automatically create all needed Folders. If you like, you can overwrite these Folders Checkmk Attributes, including the Visible Name.</p> <p>The Syntax for that, has nothing to do with the Jinja Syntax, but you can place Jinja Variables in it.  You can use in the \"Move to Folder\" rule, at every Folder Level you want to. Just add the Attributes after a Pipe to the Folder name. Like this:</p> <pre><code>/my_folder | {'title': 'My Nice title', 'tag_something': 'something'}\n</code></pre> <p>Same Example when the Folder comes from Jinja, please note where the Pipe is placed:</p> <pre><code>/{{my_jinja_var}} | {'title': 'My Nice title', 'tag_something': 'something'}\n</code></pre> <p>And Finally, using Jinja in the Attributes:</p> <pre><code>/{{my_jinja_var}} | {'title': '{{var_containing_title}}', 'tag_something': 'something'}\n</code></pre>"},{"location":"checkmk/folder_pools/","title":"Folder Pools","text":"<p>A Folder Pool is used if you want to import a high number of Hosts into Checkmk, but automatically spread them over your Sites. This is archived when you define Folder Pools in Checkmk\u2192Folder Pools, and define the Number of total Seats. A Seat is a Place in this Folder. The Folders will be created in Checkmk and you just need to link them to your remote sites. In the CMDB Syncer, you then need to define an CMK Export Rule which match for the Hosts you want. Please note that Folder pools will be added to the normal Folder hierarchies, if multiple Rules match. You can prevent that using the Last Match option for Rules.</p> <p>CMK Syncer will also automatically free the seat in the pool if you ignore the hosts, or nor folder_pool Rule matches any more.</p> <p>You can set them up in: Modules \u2192 Checkmk \u2192 Folder Pools</p>"},{"location":"checkmk/groups_management/","title":"Groups Management","text":"<p>The Group Management Feature let you create contact-, Host- and Service-Groups based on Attributes you get from your Hosts.</p> <p>The Syncer has a local Cache for all groups he created. That can be found in Rules \u2192 Checkmk \u2192 Object Cache. This is needed in order that the Syncer know which groups he can safely remove from Checkmk. So groups you created yourself are not touched.  If you would delete the Cache Entry, the Syncer only takes over the groups with the next sync, if they are provided from your source again.</p> <p>Also note, Checkmk has the Limitation that you can't have groups with the same name, even if it's another type. So, you can't have Contact Groups with the same name as Hostgroups. Use the Rewrite feature when needed.</p>"},{"location":"checkmk/groups_management/#rule-parameters","title":"Rule Parameters","text":"<p>The Rule to configure everything you find in:</p> <p>Modules \u2192 Checkmk \u2192 Manage Host-/Contact-/Service - Groups</p> Option Description Group Name Create Contact Group, Host Groups or Service Groups Foreach Type Iterate either an Attribute, values of an Attribute, or Objects Foreach The Attribute or Value, depending on Foreach Type.  If you use by Value, you can use a * to indicateevery Value starting with. Example:  dhcp* Rewrite Rewrite the id of the Group, by Using Jinja.  {{name}} will refer to the found value Rewrite Title Same, but for the Group's Title"},{"location":"checkmk/groups_management/#example","title":"Example","text":"<p>Let's say you Hosts have an attribute application stating their job. Now set all that the application attributes to become a Checkmk Contact Group, and use cg_ as a prefix in their Name.</p> <p>Set:</p> <ol> <li>Group Name to Contact Groups, </li> <li>Foreach Type to Foreach Attribute, </li> <li>For Foreach you set application (application is the attribute your Hosts have).</li> </ol> <p>If you just want the attribute value, you're done. But since we want the prefix, we set:</p> <ol> <li>Rewrite to cg_{{name}}</li> <li>Rewrite Title just to {{name}}. </li> </ol> <p>That's it, now \"Commit Changes\" and export the Groups to Checkmk.</p>"},{"location":"checkmk/groups_management/#export-from-commandline","title":"Export from Commandline","text":"<p>If you want to export the groups to checkmk manually, not using Cron you can do:</p> <p>./cmdbsyncer checkmk export_groups ACCOUNTNAME</p>"},{"location":"checkmk/inventorize/","title":"Checkmk Inventorize","text":"<p>The Syncer has the Function Inventorize. This is available to most of the Modules. Here describted is the Checkmk Inventorize Function. Because this Function supports a Web Based Configuration.</p> <p>Modules -&gt; Checkmk -&gt; Inventorize from Checkmk Settings</p> <p>The Default will already import all cmk Labels. In The Screenshot, you see an example how you inventorize a Service directly, and how to Access HW/SW Inventory Data of Checkmk.: </p>"},{"location":"checkmk/inventorize/#example-services","title":"Example Services","text":"<p>If you want to get either the Plugin Output, or the Service Labels, in both cases you need to configure the exact Service Name. Regex is possible only for Labels.</p>"},{"location":"checkmk/inventorize/#example-labels","title":"Example Labels","text":"<p>You can use a Wildcard (*) to filter the Labels you would like to get from the hosts.</p>"},{"location":"checkmk/inventorize/#example-hwsw-inventory","title":"Example HW/SW Inventory","text":"<p>Since the HW/SW Inventory can contain a vast amount of data, it is not inventorized per default. Also, you need to set the inventory tree you want to get. In This Example, we get the Operating System Data.</p> <p>To get the Network Interfaces, you would use:</p> <p><code>network.interfaces</code></p> <p>This would result in:</p> <p></p>"},{"location":"checkmk/inventorize/#how-to-get-checkmks-hwsw-inventory-data-names","title":"How to get Checkmk's HW/SW Inventory Data names","text":"<p>First figure out what you need, and export the Inventory as JSON: </p> <p>In this JSON you now find the Keys: software and os. That Leads to the sofware.os in the Configuration </p> <p>So as result this would be <code>software.os</code></p> <p>This logs like: </p>"},{"location":"checkmk/inventorize/#commandline","title":"Commandline","text":"<p>To run the inventorize from the commandline, run this command:</p> <p>./cmdsyncer checkmk inventorize_hosts ACCOUNT</p>"},{"location":"checkmk/password_store/","title":"Checkmk Password Manager","text":"<p>You can use the Syncer to create and update entries for the Checkmk Password Manger. This feature fully works beginning with 3.9.0. The Passwords you enter inside the Syncer, will be encrypted inside the Database. But the Key to decrypt, is stored in your local_config.py. If you change the key there, you need to Update the Passwords.</p> <p>The Syncer needs to be able to decrypt the password, before its sent to Checkmk. </p>"},{"location":"checkmk/password_store/#setup","title":"Setup","text":"<p>You have to configure 1 to 1 all settings you would have to configure in Checkmk. Jinja is not yet supported.</p>"},{"location":"checkmk/recipe_checkmk_rules/","title":"Automatically Create Rules","text":"<p>Like the principle described here the Syncer can also create all Kinds of Rules, even Active Checkmk Checks.</p> <p>This Recipe will not go in Detail how to obtain the Needed Information, instead just showing the Example Syncer Rule. The Details you find in the mentioned link.</p> <p>Fist in Checkmk create one Example Rule of the Type you want, configure it the way you want.</p> <p>Copy the Rule Name and the API Value like described here and create a new Syncer Rule in </p> <p>Modules \u2192 Checkmk \u2192 Create Checkmk Setup Rules</p> <p>As Rule Condition, you set for which hosts you want to create the Checkmk Rule. Then replace in the API Value with {{HOSTNAME}} where you need it (or use with the same Syntax every other Attribute of the host) and put it in the Value Template Field. </p> <p>Most likely, in this example, the condition_label_template stays empty and you just place {{HOSTNAME}} as Condition host. Technically, you can add more than one Hostname comma separated, if this makes sense. Since this Field also supports Jinja, you can do all Jinja Magic with your Labels, which result in a Comma separated list. </p> <p>The Fields for Value Tamplate, and Condition Template of course also support Jinja</p> <p>This is what Active Checks for Certificates would look like:</p> <p></p> <p>Result in Checkmk for that:</p> <p></p>"},{"location":"checkmk/recipe_contact_groups/","title":"Manage Checkmk Contact Groups","text":"<p>If you want to manage contact groups with the Syncer including the creation of the assignment rules, some things need to be prepared.</p> <ol> <li>You need to have Hosts with the Attributes which have the Names of the wanted groups.</li> <li>You have to create these groups. This is described here: Groups Management</li> <li>You have to create the Assignment Rules. This can be done with the Rules Management Feature.</li> </ol> <p>As a simple Example, we want to create Contact Groups for Location and Operating System of the Host.</p>"},{"location":"checkmk/recipe_contact_groups/#the-attributes","title":"The Attributes","text":"<p>Using the Import, or the Inventory functions, the Hosts must have the Attributes. In our example, we go with: os and location.</p> <p></p>"},{"location":"checkmk/recipe_contact_groups/#the-groups-rule","title":"The Group's Rule","text":"<p>First we create the Rule for creating the Groups. Modules \u2192 Checkmk \u2192 Manage Host-/Contact-/Service- Groups Since the information is clean, you don't need to fill the Rewrite or the Rewrite Title. But if you want to change something, could do for example: Rewrite: cg_{{name|lower}} Rewrite Title: {{name|capitalize}} Note: The Screenshot show Regex instead of the new Rewrite Fields</p> <p></p> <p>The sync will send them then to Checkmk:</p> <p></p> <p>Where you find them:  (Please note that in the current Version, no syncer Prefixes needed any more because of an internal cache). </p> <p>HINT: If you have values like contact_1 to contact_x, you can also use contact_* as a Wildcard for the value to trigger all values starting with the string. Only works at the End of the string.</p>"},{"location":"checkmk/recipe_contact_groups/#the-assignment-rule","title":"The Assignment Rule","text":"<p>Now you create a normal Checkmk rule. Even that this example shows the Assignment of Hosts to Contact groups, you can adapt it to every other Rule type.</p>"},{"location":"checkmk/recipe_contact_groups/#figure-out-the-rule-properties","title":"Figure out the Rule properties","text":"<p>To configure the Syncer, you need to have the Rule properties. You can find them, when you navigate to the rule in Checkmk:</p> <p>You need to Ruleset Name: </p> <p>And the Value Representation of it:  Then: </p> <p>You notice the syncer_id prefix in there. </p>"},{"location":"checkmk/recipe_contact_groups/#setup-the-rule","title":"Setup the Rule","text":"<p>Modules \u2192 Checkmk \u2192 Create checkmk Setup Rules</p> <p>This Rule now can have conditions, that is useful if you want to use {{hostname}} as a placeholder.  In our case, it's only about creating a Checkmk rule, which has a simple label condition. </p> <p>This looks just like this: </p> <p>Note the {{ location }} Jinja Placeholder. With this Syntax, you can refer to every Attribute. And you can do every operation which Jinja can do. </p> <p>For os, you just repeat this step and replace location with os.</p> <p>And now we can run the export:</p> <p></p> <p>Check the Result in Checkmk: </p> <p>Thats it, after Activate the Changes it's done.</p>"},{"location":"checkmk/recipe_multiple_http_rules/","title":"Create a bunch of multiple HTTP Rules","text":"<p>In this example I explain, how you can add Multiple HTTP Checks for Website and Certificates, based on Multiple IP Addresses. </p>"},{"location":"checkmk/recipe_multiple_http_rules/#what-you-need","title":"What you need:","text":"<ul> <li>A Data Source Containing this Information (maybe just CSV?)</li> <li>One Rule in the Syncer for Each IP</li> <li>Perhaps create an Example rule for each type in Checkmk. This article will cover every step.</li> </ul>"},{"location":"checkmk/recipe_multiple_http_rules/#the-data-source","title":"The Data Source","text":"<p>For the Example I use a Simple CSV, which a Column for each of my IP Addresses, and two hosts:</p> <p></p> <p>This file I import as Main Source into the Syncer:</p> <p></p> <p>Where I find them then:</p> <p></p> <p>The Details show me the IP Attributes:</p> <p></p>"},{"location":"checkmk/recipe_multiple_http_rules/#find-out-the-rule-parameters","title":"Find out the Rule Parameters","text":"<p>As a next step, I create the two example Rules I want to have in Order to copy their API Attributes. This is documented in Detail here: Recipe Checkmk Rules</p> <p>To make the replacement of Values easier for me, i already use {{IP}} for all places, I want to have my dynamic IPs later on.</p> <p></p>"},{"location":"checkmk/recipe_multiple_http_rules/#create-the-syncer-rules","title":"Create The Syncer Rules.","text":"<p>In the Syncer change to tue CMK Rules Menue:</p> <p></p> <p>Hit the Create button and I show for the first IP Example how to set up the rule. Repeat the Step for all the other IPs.</p> <p>The Rule needs to have one condition. This is to check if the Label exists for the Host. Please note here, the Match Type is set to attribute, so the Green Host Match Field is not used. In the Blue Fields, the Attribute Name ip_1 needs to exist, but can have any content (Match ALL) </p> <p>But Since I want to have two checks for each IP, I also add two Outcomes for the Rule. The first is for the normal HTTP Check. Here I replace IP with my first label, ip_1</p> <p></p> <p>The Second Outcome is for the Certificate Check.  Here I do the same Replacements.</p> <p></p> <p>Make sure to Enable the rule and hit Save. Repeat this for ip_2 and ip_3.</p>"},{"location":"checkmk/recipe_multiple_http_rules/#sync-the-rules","title":"Sync the Rules","text":"<p>The Final Step is to sync the rules to Checkmk. Make sure to delete your example rules, of course. And no Checkmk Activation is needed, you can wait to the end. If you followed this example, don't forget to use the export_hosts to create your example hosts in Checkmk.</p> <p>To sync the rules, run export rules. In my environment, the Account name is set to mon. So, it looks like this:</p> <p></p>"},{"location":"checkmk/recipe_multiple_http_rules/#in-checkmk","title":"In Checkmk","text":"<p>Only left is to see the Outcome in Checkmk, and Activate the Changes:</p> <p></p>"},{"location":"checkmk/rules_management/","title":"Manage Checkmk Setup Rules","text":"<p>Out of the box, it's possible in Checkmk to create Rules with not much effort. This applies to Threshold Rules and also to for Rules which activate Active Checks, for example. But as soon every Check needs a custom Parameter, it gets harder to set up.</p> <p>The CMDB Syncer can help here in two Ways. He can add custom Attributes to your Hosts, which you then can use in some of the rules. This is described here</p> <p>As alternative, you can use this Feature of Syncer, to create a bigger bunch of rules. And the best here, the Syncer also deletes the rules again, if not needed.</p>"},{"location":"checkmk/rules_management/#configuration-options","title":"Configuration Options","text":"<p>Modules \u2192 Checkmk \u2192Create Checkmk Setup Rules</p> Option Description Ruleset Checkmk's Ruleset ID Folder Folder in Checkmk (Jinja Support) Folder Index Index of Rule in Folder Comment Rules Comment Value Template Jinja for the Rules Value (check in CMK) Conditon Label Template Syntax: label:value, you can use Jinja. {{HOSTNAME}} also available Condition Host Comma seperated List of Hosts, Jiunja Support including {{HOSTNAME}}"},{"location":"checkmk/rules_management/#full-examples","title":"Full Examples","text":"<ul> <li>Manage Contact Groups.  Check this Example to see how the Feature can be setup.</li> </ul>"},{"location":"checkmk/users/","title":"Mange Checkmk users","text":"<p>The Syncer can Create/ Delete or Disable Users for you.</p> <p>You find the Settings in:</p> <p>Modules \u2192 Checkmk \u2192 Manage Checkmk Users</p> <p>The Attributes there a mostly self explaining. Every entry will be either Update the User, Overwrite the Password (if set), Disable the Login (if set) or even delete the User if found (and if set)</p>"},{"location":"ciscodna/","title":"Cisco DNA Center","text":"<p>The System currently support the import of Devices and Interfaces from Cisco DNA. This is done by CLI Commands. They can be reaced with: ./cmdbsyncer cisco-dna</p>"},{"location":"csv/","title":"Functions with CSV Files","text":"<p>CSV Options are CLI only and can be access with ./cmdbsyncer csv They are used, to add Information to your Hosts, which you don't get from your CMDB, or even Mange hosts by a CSV File. </p> <p>Real live scenario here are that no all hosts have made it into the CMDB, and until then the Syncer gets them from a CSV. </p>"},{"location":"csv/#csv-format","title":"CSV Format","text":"<p>As of default, you need to separate the fields by ;, and have a Column named host, which contains your Hostname. </p> <p>All Other Columns, will be translated into either inventory (with key as prefix) or Labels. This depends on if you Import Hosts (means they are managed by the CSV), or Inventorize Hosts (means only extra Inventory Information is added to existing hosts).</p> <p>Example: <pre><code>host;label_name1;label_name2\nsrvlx100;content1;content2\n</code></pre></p> <p>This means we would have a host: srvlx100 with labels: label_name1:content1, labels_name2:content2</p>"},{"location":"csv/#account-settings","title":"Account Settings","text":"<p>Instead of passing Command Line Options, we recommend creating a Account for each file. This not only simplifiess the command line, but also enables the Syncer to use the is_master feature. This feature for can let another Plugin overtake the import from the field. </p> <p>You can use the following Settings as Custom Fields:</p> <ul> <li>hostname_field</li> <li>delimiter</li> <li>csv_path (required)</li> <li>key (only in case of inventory needed)</li> </ul>"},{"location":"csv/#command-line-options","title":"Command line Options","text":"<p>For Historic reasons, this Module was never meant to be configured via accounts. Therefore, as default the CLI accepts all the Options as Parameters. To use with an account, use <code>--account</code> to specify them.</p>"},{"location":"csv/#csv-files-and-excel-encoding","title":"CSV files and Excel \u2192 Encoding","text":"<p>If you have Coding Problems when importing, it's worth a try going to the Accounts settings and change the Encoding from <code>utf-8</code>to <code>utf-8-sig</code></p>"},{"location":"i-doit/","title":"I-Doit Sync","text":"<p>With the I-Doit Feature of the Syncer, you can Sync Informationen to I-Doit. That can be everything the Syncer knows about an Object, and could be everything. Everything means, you can use the inventory feature to import e.g. Checkmk Service Information, Checkmk HW/SW Inventory information, CSV or APIs. But thats True for every Syncer Module.</p>"},{"location":"i-doit/#how-to-set-it-up","title":"How to Set it up","text":"<p>Modules \u2192 i-doit \u2192Custom Attributes In Rule Outcomes you can define the e.g. the Templates to send to I-Doit and use Jinja Magic to access the Attributes of the Objects.</p>"},{"location":"i-doit/#category-template-examples","title":"Category Template Examples","text":"<pre><code>TBD\n</code></pre>"},{"location":"i-doit/#define-objects-object-type","title":"Define Objects Object Type","text":""},{"location":"i-doit/#define-attributes-to-use-as-objects-description","title":"Define Attributes to use as Objects Description","text":""},{"location":"internal_restapi/","title":"Rest API","text":"<p>The cmdbsyncer provides REST API endpoints for various functions. You can explore them using the integrated Swagger GUI when accessing /api/v1.</p> <p>From Version 3.10 the authentication uses the user accounts you can set in the GUI. For auth, send <code>x-login-user:USERNAME:Password</code></p>"},{"location":"internal_restapi/#ansible-endpoints","title":"Ansible Endpoints","text":"<p>These endpoints can be used to access the Ansible Inventory of the cmdbsyncer from different servers. You find an example of how it can be used with <code>ansible-playbook</code> in the ansible Subfolder.</p>"},{"location":"internal_restapi/#syncer-endpoints","title":"Syncer Endpoints","text":"<p>These endpoints are used to monitor syncer operations. The official Checkmk Syncer Monitoring Plugins are using them.</p>"},{"location":"internal_restapi/#objects-endpoints","title":"Objects Endpoints","text":"<p>With the provided <code>GET</code>/<code>POST</code>/<code>DELETE</code> endpoints it's possible to change hosts or objects inside the Syncer, and also to retrieve them. Please note that there is no <code>PUT</code> method, since you don't need to check if an object already exists before you update it. The Syncer gets or creates host objects from his database to simplify the operations.</p>"},{"location":"jdisc/","title":"Jdisc","text":"<p>Starting with Version 3.8 the Syncer has support to Import Data from JDisc.</p> <p>It's possible to Import Devices, Applications and Executables. The needed GraphQL Queries are already hardcoded into the Syncer so no need to worry.</p>"},{"location":"jdisc/#how-to-set-it-up","title":"How to Set it Up","text":"<ol> <li>Create an Account of type JDisc Devices</li> <li>Import the Data needed using a Cron Job or from the command line (./cmdbsyncer jdisc import_XXX ACCOUNTNAME)</li> </ol>"},{"location":"jdisc/#the-account-settings","title":"The Account Settings","text":"<p>In the Account Settings, you just need to set up the URL and Credentials to JDisc. Depending on which command you run later, the objects are imported automatically into the right category.</p>"},{"location":"jdisc/#rewrite-fields-like-role","title":"Rewrite Fields like role","text":"<p>You may notice that fields like roles come as a list. That means they have the following Format: ['DeviceRole', 'value']. This is not useful if you want to export that, since you need a String Value not a list. But you can fix that with the Syncer, which Supports Jinja. Use the Rewrite Attributes Part for the Module you use to export like the following example.</p> <p></p> <p>In This Example for the Attribute Name, I change it from roles to role and for the value, I convert the list to use the first value if existing, if not, fall back to undefined. The helper get_list() is used.</p>"},{"location":"jira/","title":"Jira Cloud","text":"<p>Since of Syncer 3.8.2, it's possible to Import Objects from a Jira Cloud Instance.</p>"},{"location":"jira/#account-settings","title":"Account Settings","text":"<p>As Account settings, you need to set:</p> <ul> <li>Username: The Jira Accounts Username</li> <li>Password: The API Token</li> </ul> <p>In Additional Settings you need to set:</p> <ul> <li>Workspace ID</li> <li>LQL Query, Example <code>TBD</code></li> </ul>"},{"location":"ldap/","title":"LDAP","text":"<p>The Syncer has the options to import all kind of objects from LDAP.</p> <p>To use that, you need to create an Account of the Type 'LDAP'. After saving it, the Account will provide you with some necessary fields you need to set.</p> Field Description <code>base_dn</code> Base for Import, Example: DC=Domain, DC=Domain <code>search_filter</code> Example: (&amp;objectCategory=Person)(objectClass=user)) <code>attributes</code> Fields to read, like cn <code>hostname_field</code> Field which the syncer should use to identify the object <code>encoding</code> utf-8 or ascii, depending on your server <p>Some tipsabout the Account Setting: If you import a certain type of objects, which are not hosts, mark the account as <code>is_object</code> and choose an Object Type. This way, you later can better filter the input for operations.</p>"},{"location":"ldap/#testing-the-import","title":"Testing the Import","text":"<p>You can test the Import using the commandline.</p> <p>Command: ./cmdbsyncer ldap import_objects ACCOUNTNAME</p>"},{"location":"ldap/#setting-the-process","title":"Setting the Process","text":"<p>For Production Use, setup the Job as a cron</p>"},{"location":"netbox/","title":"General","text":""},{"location":"netbox/#setup-of-netbox","title":"Setup of Netbox","text":"<p>You need at Least an API Key, to Set up the Connection as Account in Syncer. To create one, login to Netbox and switch to Admin \u2192 API Token. This Token you have to set as Password for the Syncer Account you use with Netbox.</p> <p>If the Netbox Installation is a new one, also make sure to set a Default Location (Site) which is required for every Device you create.</p> <p>Also, you need to Set up a Reference Field for the Devices, that the Syncer can mark systems owned by him. This Field does not need to be Visible, and the Syncer uses it to store the Account ID in there. This way, the Syncer knows which Device was created by him. </p> <p></p> <p>The final Step then is the configuration for the Attributes you want to sync; otherwise there will be an exception when you try to export your Hosts. </p>"},{"location":"netbox/#special-options-in-rules","title":"Special Options in Rules","text":"<p>The Rules support some options which simplify some cases. Refer to here to learn more.</p>"},{"location":"netbox/#decommission-data","title":"Decommission Data","text":"<p>Hosts and Virtual Machines are automatically Decommissioned in case they are not longer part of the Syncer Database, but have been created by it.</p>"},{"location":"netbox/Interfaces/","title":"DCIM Interfaces","text":"<p>The Syncer can create Interfaces in Netbox.  This can be set in Modules -&gt; Netbox -&gt; DCIM Interfaces.</p> <p>As in other Syncer Functions, you can match your Host Attributes to Netbox Attributes.  Here you will find some Examples.</p> <p>The \"ID of Assigned Device\" for example, can be found in an Attribute like \"accountname_device_id\". This attribute is automatically set when you used the device export of the Syncer. But the name depends on the Account Name you used. The part accountname is replaced by this Accounts Name. </p> <p>An example value, if the Account's name is netbox, would be <code>{{netbox_device_id}}</code> The Brackets are the Jinja Syntax for Variables.</p> <p>Like the Device Export, also this Interface Export will automatically add information to the Host inside the Syncer. This then can be used to Export IP Addresses.</p>"},{"location":"netbox/Interfaces/#full-example","title":"Full Example","text":""},{"location":"netbox/Interfaces/#hosts-attributes","title":"Hosts Attributes","text":"<p>In the Example, the Host as the Attribute <code>mainip4transport</code> with the following Value: <pre><code>{'hostnames': [], 'ipAddress': '172.30.50.121', 'subnetMask': '255.255.255.0', 'networkInterface': {'physicalAddress': '00:50:56:96:25:0c', 'index': 2, 'extendedDescription': 'ens192', 'operationalStatus': 'Up', 'speed': 10000000000}, 'network': {'name': None, 'nameManuallyConfigured': None, 'networkBaseAddress': '172.30.50.0', 'subnetMask': '255.255.255.0'}}\n</code></pre></p> <p>And Some others which you see here: </p>"},{"location":"netbox/Interfaces/#accessing-host-attributes","title":"Accessing Host Attributes","text":"<p>The Following Functions can be used, to Access these Attributes:</p> <p></p> <p>To get the Examples Description: <pre><code>{{mainip4transport['networkInterface']['extendedDescription']}}\n</code></pre></p>"},{"location":"netbox/Interfaces/#accessing-ip-and-convert-subnet","title":"Accessing IP and Convert Subnet.","text":"<p>Our Example contains a IP Address and a Subnet Mask. But that does not meat Netbox Requirements for the IP Address. We need the form <code>127.30.50.121/32</code>. Luckly the Syncer has a helper to convert that: <code>get_ip4_network()</code></p> <p>We just pass the IP Address and the Subnet Mask to it. In the Example, the fields <code>mainipaddress</code> and <code>mainip4transport</code> to create a String (<code>+</code>) to create <code>127.30.50.21/255.255.255.0</code> and from there it's passed to the Helper:</p> <pre><code>{{ get_ip_interface(mainipaddress+\"/\"+mainip4transport['subnetMask']) }}\n</code></pre>"},{"location":"netbox/Interfaces/#use-list-variables","title":"Use List Variables","text":"<p>This Rule can also use List Mode. Here are some Examples for fields. The Information of course need to Exist on the Syncer Objects.</p>"},{"location":"netbox/Interfaces/#for-name","title":"For Name:","text":"<p><pre><code>{{HOSTNAME }} \n{% if LIST_VAR['extendedDescription'] %}\n {{LIST_VAR['extendedDescription']}}\n{%else%}\n {{LIST_VAR['description']}}\n{% endif %}\n</code></pre> Here the Interface name Starts with the Host's Name, then if existing the extended description, else the normal description.</p>"},{"location":"netbox/Interfaces/#interfaces-address","title":"Interfaces Address","text":"<p><pre><code>{% for ip in LIST_VAR['ip4Transports'] %}\n{% set ip_address = ip['ipAddress'] %}\n{% set subnet_mask = ip['subnetMask'] %}\n{% if not subnet_mask%}\n{% set subnet_mask = \"255.255.255.0\" %}\n{% endif %}\n{{ get_ip_interface(ip_address+'/'+subnet_mask) }},\n{% endfor %}\n</code></pre> To helper Variables are used, to store the IP to <code>ip_address</code>, and the subnet to <code>subnet_mask</code>. And then there is a Fallback if <code>subnet_mask</code> is empty.</p>"},{"location":"netbox/account/","title":"Netbox Account Settings","text":"<p>The Following Extra Configuration is possible for Netbox Accounts</p> Field Description <code>rewrite_hostname</code> Imported Hostnames are rewritten with Jinja <code>verify_cert</code> <code>True</code> for Certificate validation, else `False' <code>import_filter</code> Comma seperated key:value pairs which will be passed as filters for vm or device import. Note: Custom Field Names need to start with cf_"},{"location":"netbox/contacts/","title":"Export Contacts","text":"<p>You can create Contacts in Netbox. This module is set up, like the other Modules. Nothing Special to now.</p>"},{"location":"netbox/contacts/#how-to-test-export","title":"How to Test export","text":"<p>To test, you can use the Commandline: ./cmdbysncer netbox export_contacts ACCOUNT</p>"},{"location":"netbox/dataflow/","title":"Dataflow Plugin","text":"<p>The Syncer can be used to synchronize to the Third-Party Plugin Data flow. But this is a bit more complicated as the other Netbox Functions.</p> <p>Dataflow as multiple Models. But to set it up, start with the creation of \"Field Definitions\". There you map the Fields of Netbox to the Attributes of your Syncer Objects. You can also create Multiple Rules for the Same model if needed.</p> <p>The second Step, is to create a 'Model Definition'. There you choose the Target Model and Connect the Field Definitions you created before.</p>"},{"location":"netbox/dataflow/#field-definitions","title":"Field Definitions","text":""},{"location":"netbox/dataflow/#field-name","title":"Field Name","text":"<p>The Field Name, as given in Netbox. If it is a Custom Field, you can check <code>Is Netbox Custom Field</code>.  If the Field is a \"List Field\", Like the list of Tags or a custom created one, you need to check <code>Is Netbox List Field</code>.</p>"},{"location":"netbox/dataflow/#field-value","title":"Field Value","text":"<p>The Field Value can use extended Jinja Syntax. Also, you can create Multiple Outcomes with one rule. When checked <code>Expand Value as List</code>, you can provide a comma separated list here. No need to do in manually, this can also be done with Jinja, here is an Example:</p> <p><pre><code>{% for app in jdisc_applications__list %}{{app['application']['name']}},{% endfor %}\n</code></pre> Note the Comma after the bracket inside the loop.</p>"},{"location":"netbox/dataflow/#use-to-idenitfy","title":"Use to Idenitfy","text":"<p>The Syncer needs to know which of your Attributes should be the used as the Field which identifies the Object in Netbox. Its necessary that exactly one Field is set as such.</p>"},{"location":"netbox/devices/","title":"DCIM Devices","text":"<p>If you want to sync your Devices to Netbox, you find all information how to set this up here.</p>"},{"location":"netbox/devices/#fields","title":"Fields","text":"<p>With Version 3.8 the Syncer exports all Fields by their name. No need to know any Netbox IDs anymore. Every field supports Jinja. So you only need to write your Attributes in Jinja Style as Variables. So don't forget to add the brackets around. Here are some advanced Examples including Jinja Code Examples for more advanced problems.</p> <p></p> <p>Some fields are always required in order that the call can work. Therefore, all fields with * in front of the Name need to be set.</p>"},{"location":"netbox/devices/#fields-which-need-reference","title":"Fields which need Reference","text":"<p>In Some cases, the Data Model of Netbox requires references to differnd Objects. Like a Device needs a Device Type, a Device Type needs a Manufacturer. The Syncer creates these objects as well, up to three levels deep, fully automatically.</p>"},{"location":"netbox/devices/#netbox-api-versions","title":"Netbox Api Versions","text":"<p>WARNING: Netbox did a Change in their API and changed a Field from device_role to just role. Please note that you need to update your syncer if you run in a problem about missing device_role payload. The Syncer in default always works with the current Netbox Version. To support older Versions, a chance to make this work is to Downgrade the pynetbox module used by syncer</p>"},{"location":"netbox/ipaddresses/","title":"IPAM IP Addresses","text":"<p>This Module Targets the IP Address management in Netbox. If you used the Syncer to export the Interfaces, you can easily also match the IP Addresses to the correct Interface.</p> <p>In this case, you will find two Attributes with your Hosts: For DCIM Interfaces its: <code>Netbox_dcim_interfaces</code> and for the Virtual Interfaces is <code>Netbox_virt_interfacs</code></p> <p>This is, what it looks like:</p> <pre><code>[\n {'port_name': 'sysname lo0',\n  'netbox_if_id': 1462,\n  'ipv4_addresses': ['127.0.0.1/8'], \n  'ipv6_addresses': []},\n {'port_name': 'sysname en0; Product: Virtual I/O Ethernet Adapter (l-lan)', \n  'netbox_if_id': 1461,\n  'ipv4_addresses': ['172.30.71.204/24', '172.30.71.154/28'],  \n  'ipv6_addresses': []\n }\n]\n</code></pre> <p>The Name always depends on the Account Name you're using for Netbox. In this Example, it is set to \"Netbox\".</p> <p>From there it's easy to access the Data. That is to set in Modules \u2192 Netbox \u2192 IPAM IP Addresses.</p> <p></p> <p>Here the Feature List Mode is used. It allows you to iterate over a Variable quite Easily.</p>"},{"location":"netbox/prefixes/","title":"Syncronise IP Prefixes to Netbox","text":"<p>To Sync IP Prefixes to Netbox, find the Module: Modules \u2192 Netbox \u2192 IPAM Prefix</p>"},{"location":"netbox/prefixes/#single-attribute-to-prefix","title":"Single Attribute to Prefix","text":"<p>Set at least the Action Prefix as a Field. In Param, you can use Jinja. From there we need the format IP/SUBNET which can come from multiple Attributes of the Host. The System automatically makes sure, that there a no duplicate Updates</p>"},{"location":"netbox/prefixes/#convert-an-ip-with-subnet-to-prefix","title":"Convert an IP with Subnet to Prefix","text":"<p>If you know the IP and the Subnet, you don't need to calculate the Prefix. The Syncer has a helper Function for that.  </p> <p><pre><code>'{{get_ip_network(ip+'/'+subnet)}}'\n</code></pre> In the example is given that you have an attribute called ip, and one called subnet.</p>"},{"location":"netbox/prefixes/#export-a-list-of-prefixes-per-object","title":"Export a List of Prefixes per Object","text":"<p>If you have more than one IP, you can build a List in the Param Field. The Syncer will automatically detect if you try to build a Python List.</p> <p>A list looks like this: <pre><code>['entry1','entry2']\n</code></pre></p> <p>So if you have an Attribute with an list of IP and Subnets, it could look like this:</p> <pre><code>[{% for ip in attribute %}\n    '{{get_ip_network(ip)}}',\n{% endfor %}]\n</code></pre> <p>Note the <code>[</code> add the beginning, and the <code>]</code> add the end' Also every entry is wrapped in ticks, and have a comma at the end.</p>"},{"location":"netbox/prefixes/#iterate-a-list-variable-with-multiple-ips","title":"Iterate a List Variable with multiple IPs","text":"<p>If you use the Syncer to add the IPs and Interfaces to Netbox, the objects will have helper Variables with all the Data you need.</p> <p>They always start with the Name of the Account you use, in this Example it's \"Netbox\"</p> <p>For DCIM Interfaces its: <code>Netbox_dcim_interfaces</code> and for the Virtual Interfaces is <code>Netbox_virt_interfacs</code></p> <p>This Fields looks like this:</p> <pre><code>[\n {'port_name': 'sysname lo0',\n  'netbox_if_id': 1462,\n  'ipv4_addresses': ['127.0.0.1/8'], \n  'ipv6_addresses': []},\n {'port_name': 'sysname en0; Product: Virtual I/O Ethernet Adapter (l-lan)', \n  'netbox_if_id': 1461,\n  'ipv4_addresses': ['172.30.71.204/24', '172.30.71.154/28'],  \n  'ipv6_addresses': []\n }\n]\n</code></pre> <p>As you see, the key ipv4_addresses contain also a list. So a List in the List of Interfaces.</p> <p>Now we combine two features, the Export a List as described before. And the 'Use List Variable Name'. First activate it, by check \"Use list Variable\". Then enter the Variable Name to iterate over. In the \"Param\" Field, you then can use the Placeholder <code>LIST_VAR</code> to access the Loop Variable of the iteration of the list. </p> <p>Here the full example using the explained helper variable:</p> <p></p> <p>To copy: <pre><code>[{% for ip in LIST_VAR['ipv4_addresses'] %}\n'{{get_ip_network(ip)}}',\n{% endfor %}]\n</code></pre> Find all documentation about the List Feature here.</p>"},{"location":"netbox/vms/","title":"VMs","text":"<p>The Export of VMs is similar to the export of Devices.</p> <p>To export Virtual Machines, Netbox has the requirement to set a Cluster. You can create them before, and set the Clustername as a Field, but the Syncer has also the option to create clusters if needed.</p> <p>In all Fields, you can use advanced Jinja Syntax.</p>"},{"location":"rest_json/","title":"Rest and Json","text":"<p>The Syncer allows you to directly import Json Files or Simple Rest APIs, which return plain Json and don't have special Authentication.</p>"},{"location":"rest_json/#rest-api","title":"Rest API","text":"<p>Everything is configured using an Account. The Following Options are available:</p> Option Description <code>auth_type</code> Empty if you want a Header based auth, else <code>Basic</code> or <code>Digest</code> <code>cert</code> Path to a Certificate for Certificat Based auth <code>request_headers</code> Send Custom Headers like for Auth or Content Type <code>data_key</code> Empty or key where the Data will be found. <code>hostname_field</code> In which field can the Hostname be found <code>rewrite_hostname</code> Jinja if you want to rewrite the hostname <code>method</code> The request can be changed from GET to POST. <code>post_body</code> If POST mode, specify the JSON Body here"},{"location":"rest_json/#json-file","title":"JSON File","text":"<p>Like for Rest API, everthing is configured in an Account. Here, you just need to set the Path to the File.  Fields like hostname_field are described above in the description of Rest API</p>"},{"location":"rest_json/#when-using-the-data_key","title":"When Using the  data_key","text":"<p>The data_key can be confusing. Here two examples to see what it's for.</p> <p>In this Example, data_key needs to be 'results' <pre><code>{'results': [{data},{data}]}\n</code></pre></p> <p>In this case, the data key needs to be empty <pre><code>[{data},{data}]\n</code></pre></p>"},{"location":"sys/","title":"SYS Module","text":"<p>The sys Module contains Internal Functions. It can only be used in the CLI. You reach it with ./cmdbsyncer sys</p> Option Description create_user Create a New User, or reset Password/ 2FA Code delete_all_hosts Delete all Hosts, add a Account name to filter delete_cache Delete Hosts Cache delete_inventory Delete Hosts Inventory Information maintenance Run Cleanup of Hosts, use best with Account Will delete Hosts not found any more reset_folder_pools Reset Usage of Checkmk Folder Pools. self_configure Seed default configurations if needed show_accounts Nice Table with list of all configured Accounts.Comes in Handy when working on the CLI"},{"location":"updates/changelog/","title":"Changelog","text":""},{"location":"updates/changelog/#general-when-update","title":"General when Update","text":"<p>Please always check before you update here, if there are changes you need to consider.</p> <p>After always, please run: <pre><code>./cmdbsyncer sys self_configure\n</code></pre> This will automatically adapt config changes if needed, and add needed default values to the local_config.py if you don't have them. For example, the Cryptography key.</p>"},{"location":"updates/changelog/#to-version-310","title":"To Version 3.10","text":"<p>The authentication for the REST API now works only with users, no longer with accounts  You need to adapt all your scripts that are working with the Syncer Rest API. This change is required because it's planned to implement a permission management for the API later.</p>"},{"location":"updates/changelog/#to-version-39","title":"To Version 3.9","text":"<p>If you had Checkmk Custom Attribute Rules, which created multiple outputs because you did a comma seperation, the seperation sign changed from comma to double (||) pipes. Please adapt your rules after Update</p> <p>Also, all account passwords are now encrypted. If you run self_configure, everything will be migrated automatically. </p>"},{"location":"updates/changelog/#to-version-38","title":"To Version 3.8","text":""},{"location":"updates/changelog/#format-of-imported-data","title":"Format of Imported Data","text":"<p>Before 3.8, every imported Label Value was converted to a String. That was fine in the beginning with simple Labels. But since more and more Jinja is used, it was a pain that Data structures, like Lists and Dicts, first had to be converted back from their string state.  This Conversation does not happen anymore. A dict stays a dict, a list stays a list. But also, a None, False or True, stays like that.  Does this affect you: In short: No. Because if you us normal matches, the value will still convert to a string for this match. Only if you set to Bool Match, the bool stays like the origin. Although the Bool Match even can convert the strings of True, None or False back. So nothing to worry about. But why then, this all? In Jinja Templates, you now have all the Flexibility you need to customize Data, Loop etc.pp to your need. </p>"},{"location":"updates/changelog/#mongodb-update","title":"Mongodb Update","text":"<p>This only applies if you're using the docker-compose files shipped with the Syncer. Otherwise, you can skip that Part. The Version of Mongo Updates from 4.4 to 7.0.14 You can either Back up your Data with the Syncers export function and start with and Empty Database again. Or just first change the MongoDB Version in the Docker File to 5.0, start and login to Syncer, then 6.0, start and login to Syncer and finally to the 7.0.14.  In the Future I will directly add the new Versions the moment they are Stable. So there will not be such a Big Step anymore.</p>"},{"location":"updates/changelog/#netbox","title":"Netbox","text":"<p>The Netbox Module is completely rewritten and therefore more flexible and simpler to use. But the catch is, that you need to update your rules. In short:  For Attributes you need to use Jinja Syntax {{ATTRIBUTE}} and no need for Netbox ID's anymore, you can directly use the Name. If you have a manual setup, make sure to update the python requirements. A new requirement is pynetbox.</p>"},{"location":"updates/changelog/#vm-import","title":"VM Import","text":"<p>The Import of VMs from Inbox is not longer part of the device import. It's an own command which has to be set. Also, since now pynetbox is used, it's possible that attribute names change. </p>"},{"location":"updates/changelog/#to-version-37","title":"To Version 3.7","text":"<p>After Update, please commit the changes, otherwise there will be an exception on Checkmk Export</p>"},{"location":"updates/changelog/#general","title":"General","text":"<ul> <li>GUI: Simplified Interface, clearer Descriptions in Menu</li> <li>Export of Hosts and Tags to Checkmk, use now all available Processing Power to calculate Rules before importing.</li> <li>Bulk Operations for Checkmk are now Enable as Default</li> </ul>"},{"location":"updates/changelog/#supported-versions","title":"Supported Versions","text":"<ul> <li>Checkmk: API Calls are Adapted to Checkmk 2.3 and some functions may not work on 2.2<ul> <li>Checkmk Rules: On 2.2 the rules will delete and created again all the time due an API change in Checkmk. </li> </ul> </li> <li>SET local_config: 'CMK_SUPPORT': '2.2' to make version better compatible to old 2.2</li> </ul>"},{"location":"updates/changelog/#interaction-needed","title":"Interaction Needed","text":"<ul> <li>CSV: On Import, Hostnames are only set to lowercase if set in local_config.py. No longer as Default. See Local Config</li> <li>MySQL: On Import, Hostnames are only set to lowercase if set in local_config.py. No longer as Default. See Local Config</li> <li>Mssql: On Import, Hostnames are only set to lowercase if set in local_config.py. No longer as Default. See Local Config</li> <li>Checkmk: Export Rule Value of Folder is deprecated. Replaced by Jinja Support of normal Move Folder Rule.</li> <li>General: Jina Placeholder for Hostsname is now always Uppercase HOSTNAME.</li> <li>Checkmk: The Checkmk API once allowed, accidentally, that a host could be converted to a cluster. Since that is no longer possible, the Syncer now deletes hosts which should become a cluster to recreate them as such.</li> <li>General: Config introduced \"CRYPTOGRAPHY_KEY\". Please overwrite it, since it is used to encrypt stored passwords in the database</li> <li>CRON: The Maintenance Cronjob had a Typo. After Update, you need to reelect this command in the config of the cron group. </li> </ul>"},{"location":"updates/changelog/#new-features","title":"New Features","text":"<ul> <li>Checkmk:Folder names can now set that they will not be lowercase to keep their case. See Checkmk Config</li> <li>Checkmk: Folders can now get Attributes and Different Names, managed by Syncer.</li> <li>Checkmk: Move to Folder Rule now Supports full Jinja and Replaces Value of Folder rule</li> <li>Checkmk: It's possible to create folders but not move the host in</li> <li>Checkmk: The Debug Page shows now the Rule Debug was before only was possible in cli</li> <li>Checkmk: Export --dry-run and --save-requests to test or just save needed actions to run them later or archive them</li> <li>Checkmk: Support to Manage DCD (Dynamic Configuration) Rules</li> <li>Checkmk: Support to manage Password Store</li> <li>Checkmk: Detailed logging (if enabled) for changes made</li> <li>Global: Changes on Import hosts for Labels are now logged inside the Host Objects log</li> <li>LDAP: Added Support for Inventorize</li> </ul>"},{"location":"updates/changelog/#minor-changes","title":"Minor Changes","text":"<ul> <li>Checkmk: Modul for Checkmk Rules now supports Jinja for Folder names</li> </ul>"},{"location":"updates/changelog/#to-version-35","title":"To Version 3.5","text":"<p>Version 3.5 is a Major Update which updates all required Python Modules and also  resolves older problems which can't be resolved staying compatible. So your help is needed for this one. </p> <p>These steps are only needed for the first time when you update from pre 3.5 Versions. Also when you skip 3.5 or you're working with the git versions. </p>"},{"location":"updates/changelog/#1-requirementstxt","title":"1) requirements.txt","text":"<p>The Requirements txt is now divided in 3 Files.</p> <ul> <li>requirements.txt \u2192 All you need to run the Syncer</li> <li>requirements-extras.txt \u2192 Modules like ldap/ mysql which not all users need</li> <li>requirements-ansible.txt \u2192 Everything needed for the Ansible automations</li> </ul> <p>Note: If you're using Docker, all Modules are installed automatically.</p>"},{"location":"updates/changelog/#2-module-updates","title":"2) Module Updates","text":"<p>Due to Security problems in some of the Modules,  we had to upgrade all Modules of the Framework. So after Update of the Syncers code, you need to run the pip install -r requirements.txt again. Nothing more to-do.</p>"},{"location":"updates/changelog/#3-inventory-prefix","title":"3) Inventory Prefix","text":"<p>In the past, inventory values were prefixed like name_ something. This is now changed to name__. The Problem with the old approach: cmk_ vs cmk_svc_. If you now want to clean the cache, and delete everting starting with cmk_, you will also delete the namespace cmk_svc. This effects only rules later, you created based on inventorized data. Normal Attributes from imports are not affected.</p> <p>Steps for the migration:</p> <ul> <li>Delete current Inventory: ./cmdbsyncer sys delete_inventory</li> <li>Run your inventories again</li> <li>Update the rules wich are based on Inventory Data and fix the naming. <ul> <li>cmk_ goes cmk__</li> <li>cmk_svc_ goes cmk_svc__</li> <li>csv_ goes csv__</li> <li>and so on</li> </ul> </li> </ul>"},{"location":"updates/changelog/#4-checkmk-create-tags","title":"4) Checkmk: Create Tags","text":"<p>The function is now simpler and has more power at the same time. Only Change: Instead specify a for each and refer to {{name}}, you can directly refer to the attribute.</p>"},{"location":"updates/changelog/#5-dnsservice-dhcpservice-attributes","title":"5) dns:service dhcp:service Attributes","text":"<p>In the first Version of the Syncer, there was a limit to key:value for attributes. That lead to lists where key and values were switched, to allow multiple entries. With this Version, attributes can be not only key:string but also key:list or key:dict.  You can use that in your plugins, in case you use the outcome in jinja Templates. Example: service:['dns', 'dhcp'] could in jinja be: {{ service[0] }} or: {% for svc in service %} as loop. </p>"},{"location":"yml/","title":"YML","text":"<p>The Syncer can import data directly from YML files. Due to their structure, you need some configuration to do. Here is the file example:</p> <pre><code>all:\n    vars:\n      checkmk_server_url: \"http://localhost:5000\"\n      checkmk_site: \"local\"\n\n123-07:\n    vars:\n      basisservice: local_test1\n    host:\n       - test_host1\n       - test_host2\n234-02:\n    vars:\n      basisservice: local_test2\n    host:\n       -  test_host3\n       -  test_host4\n456-01:\n    vars:\n      basisservice: local_test3\n    host:\n       -  test_host5\n       -  test_host6\n</code></pre> <p>As you see, there are multiple sections where you have a list of hosts and variables. These variables we want to add to every host of the following list.</p> <p>This can be set in the account settings. Here are the needed values to configure that example:</p> <ul> <li>name_of_host_key: <code>host</code></li> <li>name_of_variable_key: <code>vars</code></li> </ul> <p>With this config, the test_host1 would get 'basisservice':<code>local_test1</code> as well as host test_host2.2</p>"},{"location":"yml/account/","title":"YML Account Settings","text":"Field Description <code>auth_type</code> Basic or digest auth with Username/ Password <code>cert</code> HTTP Authentication via Certificate instead of user/password (set auth_type to false then) <code>verify_cert</code> Enable/ Disable Certificate Verification for the HTTP Request <code>request_headers</code> Custom Request Header <code>name_of_hosts_key</code> In which Variable can we find the List of Hosts <code>name_of_variables_key</code> In which Variable can we find the list of Variables, which you added to the same group of hosts <code>path</code> Path to the YML is provided als local file instead from a http request."}]}